[
  {
    "path": "posts/2021-08-18-sathvikhotelbookingsdatahw3/",
    "title": "sathvik_hotel_bookings_data_hw3",
    "description": "Hotel bookings Data",
    "author": [
      {
        "name": "sathvik_thogaru",
        "url": {}
      }
    ],
    "date": "2021-08-18",
    "categories": [],
    "contents": "\nImporting data\nThis data set contains a single file which compares various booking information between hotels.\n\n\nlibrary(skimr)\nlibrary(lubridate)\nlibrary(tidyverse)\n\n\n\n\n\nhotel_bookings <- read_csv(\"../../_data/hotel_bookings.csv\")\nhead(hotel_bookings)\n\n\n# A tibble: 6 × 32\n  hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n  <chr>              <dbl>     <dbl>            <dbl> <chr>           \n1 Resort Hotel           0       342             2015 July            \n2 Resort Hotel           0       737             2015 July            \n3 Resort Hotel           0         7             2015 July            \n4 Resort Hotel           0        13             2015 July            \n5 Resort Hotel           0        14             2015 July            \n6 Resort Hotel           0        14             2015 July            \n# … with 27 more variables: arrival_date_week_number <dbl>,\n#   arrival_date_day_of_month <dbl>, stays_in_weekend_nights <dbl>,\n#   stays_in_week_nights <dbl>, adults <dbl>, children <dbl>,\n#   babies <dbl>, meal <chr>, country <chr>, market_segment <chr>,\n#   distribution_channel <chr>, is_repeated_guest <dbl>,\n#   previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\nskim() is an alternative to summary(), quickly providing a broad overview of a data frame. It handles data of all types, dispatching a different set of summary functions based on the types of columns in the data frame.\n\n\nskim(hotel_bookings)\n\n\nTable 1: Data summary\nName\nhotel_bookings\nNumber of rows\n119390\nNumber of columns\n32\n_______________________\n\nColumn type frequency:\n\ncharacter\n13\nDate\n1\nnumeric\n18\n________________________\n\nGroup variables\nNone\nVariable type: character\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\nhotel\n0\n1\n10\n12\n0\n2\n0\narrival_date_month\n0\n1\n3\n9\n0\n12\n0\nmeal\n0\n1\n2\n9\n0\n5\n0\ncountry\n0\n1\n2\n4\n0\n178\n0\nmarket_segment\n0\n1\n6\n13\n0\n8\n0\ndistribution_channel\n0\n1\n3\n9\n0\n5\n0\nreserved_room_type\n0\n1\n1\n1\n0\n10\n0\nassigned_room_type\n0\n1\n1\n1\n0\n12\n0\ndeposit_type\n0\n1\n10\n10\n0\n3\n0\nagent\n0\n1\n1\n4\n0\n334\n0\ncompany\n0\n1\n1\n4\n0\n353\n0\ncustomer_type\n0\n1\n5\n15\n0\n4\n0\nreservation_status\n0\n1\n7\n9\n0\n3\n0\nVariable type: Date\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\nreservation_status_date\n0\n1\n2014-10-17\n2017-09-14\n2016-08-07\n926\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nis_canceled\n0\n1\n0.37\n0.48\n0.00\n0.00\n0.00\n1\n1\n▇▁▁▁▅\nlead_time\n0\n1\n104.01\n106.86\n0.00\n18.00\n69.00\n160\n737\n▇▂▁▁▁\narrival_date_year\n0\n1\n2016.16\n0.71\n2015.00\n2016.00\n2016.00\n2017\n2017\n▃▁▇▁▆\narrival_date_week_number\n0\n1\n27.17\n13.61\n1.00\n16.00\n28.00\n38\n53\n▅▇▇▇▅\narrival_date_day_of_month\n0\n1\n15.80\n8.78\n1.00\n8.00\n16.00\n23\n31\n▇▇▇▇▆\nstays_in_weekend_nights\n0\n1\n0.93\n1.00\n0.00\n0.00\n1.00\n2\n19\n▇▁▁▁▁\nstays_in_week_nights\n0\n1\n2.50\n1.91\n0.00\n1.00\n2.00\n3\n50\n▇▁▁▁▁\nadults\n0\n1\n1.86\n0.58\n0.00\n2.00\n2.00\n2\n55\n▇▁▁▁▁\nchildren\n4\n1\n0.10\n0.40\n0.00\n0.00\n0.00\n0\n10\n▇▁▁▁▁\nbabies\n0\n1\n0.01\n0.10\n0.00\n0.00\n0.00\n0\n10\n▇▁▁▁▁\nis_repeated_guest\n0\n1\n0.03\n0.18\n0.00\n0.00\n0.00\n0\n1\n▇▁▁▁▁\nprevious_cancellations\n0\n1\n0.09\n0.84\n0.00\n0.00\n0.00\n0\n26\n▇▁▁▁▁\nprevious_bookings_not_canceled\n0\n1\n0.14\n1.50\n0.00\n0.00\n0.00\n0\n72\n▇▁▁▁▁\nbooking_changes\n0\n1\n0.22\n0.65\n0.00\n0.00\n0.00\n0\n21\n▇▁▁▁▁\ndays_in_waiting_list\n0\n1\n2.32\n17.59\n0.00\n0.00\n0.00\n0\n391\n▇▁▁▁▁\nadr\n0\n1\n101.83\n50.54\n-6.38\n69.29\n94.58\n126\n5400\n▇▁▁▁▁\nrequired_car_parking_spaces\n0\n1\n0.06\n0.25\n0.00\n0.00\n0.00\n0\n8\n▇▁▁▁▁\ntotal_of_special_requests\n0\n1\n0.57\n0.79\n0.00\n0.00\n0.00\n1\n5\n▇▁▁▁▁\n\nData Wrangling\ntidying the data\nfinding the na values in the dataframe( row and column) using which()\n\n\nwhich(is.na(hotel_bookings), arr.ind=TRUE)\n\n\n       row col\n[1,] 40601  11\n[2,] 40668  11\n[3,] 40680  11\n[4,] 41161  11\n\n\n\nhotel_bookings[c(40601,40668,40680,41161),]\n\n\n# A tibble: 4 × 32\n  hotel      is_canceled lead_time arrival_date_year arrival_date_mon…\n  <chr>            <dbl>     <dbl>             <dbl> <chr>            \n1 City Hotel           1         2              2015 August           \n2 City Hotel           1         1              2015 August           \n3 City Hotel           1         1              2015 August           \n4 City Hotel           1         8              2015 August           \n# … with 27 more variables: arrival_date_week_number <dbl>,\n#   arrival_date_day_of_month <dbl>, stays_in_weekend_nights <dbl>,\n#   stays_in_week_nights <dbl>, adults <dbl>, children <dbl>,\n#   babies <dbl>, meal <chr>, country <chr>, market_segment <chr>,\n#   distribution_channel <chr>, is_repeated_guest <dbl>,\n#   previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\n\n\nhotel_bookings <- filter(hotel_bookings, !is.na(children)) \n\n\n\n\n\nsum(is.na(hotel_bookings))\n\n\n[1] 0\n\ntransforming data and visualizing\n\n\n(hotel_bookings<-hotel_bookings %>% \n  mutate(arrival_month = recode(arrival_date_month,\"January\"=1,\"February\"=2,\"March\"=3,\"April\"=4,\"May\"=5,\"June\"=6,\"July\"=7,\"August\"=8,\"September\"=9,\"October\"=10,\"November\"=11,\"December\"=12)))\n\n\n# A tibble: 119,386 × 33\n   hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n   <chr>              <dbl>     <dbl>            <dbl> <chr>           \n 1 Resort Hotel           0       342             2015 July            \n 2 Resort Hotel           0       737             2015 July            \n 3 Resort Hotel           0         7             2015 July            \n 4 Resort Hotel           0        13             2015 July            \n 5 Resort Hotel           0        14             2015 July            \n 6 Resort Hotel           0        14             2015 July            \n 7 Resort Hotel           0         0             2015 July            \n 8 Resort Hotel           0         9             2015 July            \n 9 Resort Hotel           1        85             2015 July            \n10 Resort Hotel           1        75             2015 July            \n# … with 119,376 more rows, and 28 more variables:\n#   arrival_date_week_number <dbl>, arrival_date_day_of_month <dbl>,\n#   stays_in_weekend_nights <dbl>, stays_in_week_nights <dbl>,\n#   adults <dbl>, children <dbl>, babies <dbl>, meal <chr>,\n#   country <chr>, market_segment <chr>, distribution_channel <chr>,\n#   is_repeated_guest <dbl>, previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\n\n\n(hotel_bookings <- hotel_bookings%>%\n  mutate(arrival_date = make_date(arrival_date_year,arrival_month,arrival_date_day_of_month)))\n\n\n# A tibble: 119,386 × 34\n   hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n   <chr>              <dbl>     <dbl>            <dbl> <chr>           \n 1 Resort Hotel           0       342             2015 July            \n 2 Resort Hotel           0       737             2015 July            \n 3 Resort Hotel           0         7             2015 July            \n 4 Resort Hotel           0        13             2015 July            \n 5 Resort Hotel           0        14             2015 July            \n 6 Resort Hotel           0        14             2015 July            \n 7 Resort Hotel           0         0             2015 July            \n 8 Resort Hotel           0         9             2015 July            \n 9 Resort Hotel           1        85             2015 July            \n10 Resort Hotel           1        75             2015 July            \n# … with 119,376 more rows, and 29 more variables:\n#   arrival_date_week_number <dbl>, arrival_date_day_of_month <dbl>,\n#   stays_in_weekend_nights <dbl>, stays_in_week_nights <dbl>,\n#   adults <dbl>, children <dbl>, babies <dbl>, meal <chr>,\n#   country <chr>, market_segment <chr>, distribution_channel <chr>,\n#   is_repeated_guest <dbl>, previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\nlooking for type of hotels booked by guests\n\n\n(hotels_info<-data.frame(table(hotel_bookings$hotel)))\n\n\n          Var1  Freq\n1   City Hotel 79326\n2 Resort Hotel 40060\n\n\n\npie(hotels_info$Freq, labels=paste(hotels_info$Var1,sep = \"=\", hotels_info$Freq), main = \"type of hotels booked by guests\")\n\n\n\n\nwhere do most of the guests come from?\n\n\n(guests_country_details <- hotel_bookings %>% \n   group_by(country) %>% \n   count() %>% \n   ungroup() %>% \n   arrange(desc(n)))\n\n\n# A tibble: 178 × 2\n   country     n\n   <chr>   <int>\n 1 PRT     48586\n 2 GBR     12129\n 3 FRA     10415\n 4 ESP      8568\n 5 DEU      7287\n 6 ITA      3766\n 7 IRL      3375\n 8 BEL      2342\n 9 BRA      2224\n10 NLD      2104\n# … with 168 more rows\n\nmost guests by top country’s\n\n\nggplot(filter(guests_country_details, n>1500))+\n  geom_bar(aes(country, n), stat = \"identity\")+\n  labs(y=\"number of guests\", title = \"most guests by country's\")+\n  coord_flip()\n\n\n\n\nhow much do guests pay for a room at each hotel?\n\n\ncity_hotel_data<-filter(hotel_bookings, hotel_bookings$hotel==\"City Hotel\")\nresort_hotel_data<-filter(hotel_bookings, hotel_bookings$hotel==\"Resort Hotel\")\n\n\n\nadr - average daily rate\n\n\n# city hotel\nsort(unique(city_hotel_data$reserved_room_type))\n\n\n[1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"P\"\n\n# resort hotel\nsort(unique(resort_hotel_data$reserved_room_type))\n\n\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"L\" \"P\"\n\ncity hotel average guests per room type\n\n\n(city_hotel_average_guests_per_room_type <- city_hotel_data %>% \n   group_by(reserved_room_type) %>% \n   summarise(guests_per_room_type = mean(adults+children)))\n\n\n# A tibble: 8 × 2\n  reserved_room_type guests_per_room_type\n  <chr>                             <dbl>\n1 A                                  1.82\n2 B                                  2.12\n3 C                                  1.64\n4 D                                  2.21\n5 E                                  2.34\n6 F                                  3.62\n7 G                                  3.29\n8 P                                  0   \n\ncity hotel average daily rate per room type\n\n\n(city_hotel_adr_per_room_type_data <- city_hotel_data %>% \n   group_by(reserved_room_type) %>% \n   summarise(adr_per_room_type = mean(adr)))\n\n\n# A tibble: 8 × 2\n  reserved_room_type adr_per_room_type\n  <chr>                          <dbl>\n1 A                               96.2\n2 B                               90.5\n3 C                               85.5\n4 D                              131. \n5 E                              157. \n6 F                              189. \n7 G                              202. \n8 P                                0  \n\nresort hotel average guests per room type\n\n\n(resort_average_guests_per_room_type <- resort_hotel_data %>% \n   group_by(reserved_room_type) %>% \n   summarise(guests_per_room_type = mean(adults+children)))\n\n\n# A tibble: 10 × 2\n   reserved_room_type guests_per_room_type\n   <chr>                             <dbl>\n 1 A                                  1.80\n 2 B                                  2   \n 3 C                                  3.34\n 4 D                                  2.00\n 5 E                                  1.99\n 6 F                                  2.05\n 7 G                                  3.37\n 8 H                                  3.69\n 9 L                                  2.17\n10 P                                  0   \n\n##resort hotel average daily rate per room type\n\n\n(resort_hotel_adr_per_room_type_data <- resort_hotel_data %>% \n   group_by(reserved_room_type) %>% \n   summarise(adr_per_room_type = mean(adr)))\n\n\n# A tibble: 10 × 2\n   reserved_room_type adr_per_room_type\n   <chr>                          <dbl>\n 1 A                               76.2\n 2 B                              105. \n 3 C                              161. \n 4 D                              104. \n 5 E                              114. \n 6 F                              133. \n 7 G                              168. \n 8 H                              188. \n 9 L                              125. \n10 P                                0  \n\nvisualizing Average daily rate of reserved room type at city hotel and resort hotel\n\n\nggplot(city_hotel_adr_per_room_type_data, aes(x=reserved_room_type, y= adr_per_room_type))+\n  geom_bar(stat = \"identity\",fill = \"steelblue\", width = .5)+\n  labs(x=\"reserved room type\", y=\" average daily rate per room\", title = \"Average daily rate of reserved room type at city hotel\")+\n  theme(plot.title = element_text(size = 14, hjust = 0.5, face = \"bold\"))\n\n\n\n\n\n\nggplot(resort_hotel_adr_per_room_type_data, aes(x=reserved_room_type, y= adr_per_room_type))+\n  geom_bar(stat = \"identity\",fill = \"steelblue\", width = .5)+\n  labs(x=\"reserved room type\", y=\" average daily rate per room\", title = \"Average daily rate of reserved room type at resort hotel\")+\n  theme(plot.title = element_text(size = 14, hjust = 0.5, face = \"bold\"))\n\n\n\n\nhow does the price per night varry in the year in each hotel?\ncity hotel\n\n\ncity_room_prices_monthly <-select(city_hotel_data, arrival_date_month, adr)\n(city_room_prices_monthly <- city_room_prices_monthly %>%\n    group_by(arrival_date_month) %>%\n    summarise(mean_room_prices = mean(adr)) %>% \n    ungroup() %>% \n  arrange(desc(mean_room_prices)))\n\n\n# A tibble: 12 × 2\n   arrival_date_month mean_room_prices\n   <chr>                         <dbl>\n 1 May                           122. \n 2 June                          119. \n 3 August                        115. \n 4 April                         111. \n 5 July                          111. \n 6 September                     110. \n 7 October                       100. \n 8 March                          92.6\n 9 December                       88.8\n10 November                       88.1\n11 February                       85.1\n12 January                        82.6\n\n\n\nplot <- ggplot(city_room_prices_monthly)+\n  geom_bar(aes(arrival_date_month, mean_room_prices),stat = \"identity\")+\n  labs(x=\"arrival_date_month\", y=\" mean_room_prices\", title = \"mean room prices over the year at city hotel\")+\n  theme(plot.title = element_text(size = 14, hjust = 0.5, face = \"bold\"))\n  \n\nplot +\n  scale_x_discrete(limits = c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \n          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"))\n\n\n\n\nresort hotel\n\n\nresort_room_prices_monthly <-select(resort_hotel_data, arrival_date_month, adr)\n(resort_room_prices_monthly <- resort_room_prices_monthly %>%\n    group_by(arrival_date_month) %>%\n    summarise(mean_room_prices = mean(adr)) %>% \n    ungroup() %>% \n  arrange(desc(mean_room_prices)))\n\n\n# A tibble: 12 × 2\n   arrival_date_month mean_room_prices\n   <chr>                         <dbl>\n 1 August                        187. \n 2 July                          155. \n 3 June                          110. \n 4 September                      93.3\n 5 May                            78.8\n 6 April                          77.8\n 7 December                       69.0\n 8 October                        62.1\n 9 March                          57.5\n10 February                       55.2\n11 January                        49.5\n12 November                       48.3\n\n\n\nplot <- ggplot(resort_room_prices_monthly)+\n  geom_bar(aes(arrival_date_month, mean_room_prices),stat = \"identity\")+\n  labs(x=\"arrival_date_month\", y=\" mean_room_prices\", title = \"mean room prices over the year at resort hotel\")+\n  theme(plot.title = element_text(size = 14, hjust = 0.5, face = \"bold\"))\n  \n\nplot +\n  scale_x_discrete(limits = c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \n          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"))\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-08-18-sathvikhotelbookingsdatahw3/sathvik_hotel_bookings_data_hw3_files/figure-html5/unnamed-chunk-11-1.png",
    "last_modified": "2021-08-18T15:31:16-04:00",
    "input_file": "sathvik_hotel_bookings_data_hw3.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-18-sathvikirisdatahw2/",
    "title": "sathvik_iris_data_hw2",
    "description": "the Iris dataset",
    "author": [
      {
        "name": "sathvik_thogaru",
        "url": {}
      }
    ],
    "date": "2021-08-18",
    "categories": [],
    "contents": "\nloading the iris dataset from the datasets package and running summary statistics on the iris data\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\nfinding the column nammes of the data\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\" \n[5] \"Species\"     \n\ndim()is used to find the dimensions of the data\n\n[1] 150   5\n\nskim() is an alternative to summary(), quickly providing a broad overview of a data frame. It handles data of all types, dispatching a different set of summary functions based on the types of columns in the data frame.\n\nTable 1: Data summary\nName\niris\nNumber of rows\n150\nNumber of columns\n5\n_______________________\n\nColumn type frequency:\n\nfactor\n1\nnumeric\n4\n________________________\n\nGroup variables\nNone\nVariable type: factor\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\nSpecies\n0\n1\nFALSE\n3\nset: 50, ver: 50, vir: 50\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nSepal.Length\n0\n1\n5.84\n0.83\n4.3\n5.1\n5.80\n6.4\n7.9\n▆▇▇▅▂\nSepal.Width\n0\n1\n3.06\n0.44\n2.0\n2.8\n3.00\n3.3\n4.4\n▁▆▇▂▁\nPetal.Length\n0\n1\n3.76\n1.77\n1.0\n1.6\n4.35\n5.1\n6.9\n▇▁▆▇▂\nPetal.Width\n0\n1\n1.20\n0.76\n0.1\n0.3\n1.30\n1.8\n2.5\n▇▁▇▅▃\n\nthere are 4 numeric variables and 1 factor variable which is the species. there are a total of 3 unique species in the iris\n\n[1] setosa     versicolor virginica \nLevels: setosa versicolor virginica\n\nthe three species are setosa, versicolor and virginica\nploting iris\n\n\n\n\n\n\n",
    "preview": "posts/2021-08-18-sathvikirisdatahw2/sathvik_iris_data_hw2_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2021-08-18T15:31:18-04:00",
    "input_file": "sathvik_iris_data_hw2.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-16-railroad-employment-data/",
    "title": "Railroad Employment data",
    "description": "Reading in the railroad dataset",
    "author": [
      {
        "name": "Mohit-Arora",
        "url": {}
      }
    ],
    "date": "2021-08-17",
    "categories": [],
    "contents": "\n\n\nlibrary(readxl)\n  library(dplyr)\n  State_county <- read_excel(\"../../_data/StateCounty2012.xls\", skip=3)\n  \n\n\nThe data has been read in. Let’s see how it looks like -\n\n\nhead(State_county)\n\n\n# A tibble: 6 × 5\n  STATE     ...2  COUNTY               ...4  TOTAL\n  <chr>     <lgl> <chr>                <lgl> <dbl>\n1 AE        NA    APO                  NA        2\n2 AE Total1 NA    <NA>                 NA        2\n3 AK        NA    ANCHORAGE            NA        7\n4 AK        NA    FAIRBANKS NORTH STAR NA        2\n5 AK        NA    JUNEAU               NA        3\n6 AK        NA    MATANUSKA-SUSITNA    NA        2\n\ntail(State_county)\n\n\n# A tibble: 6 × 5\n  STATE                                       ...2  COUNTY ...4  TOTAL\n  <chr>                                       <lgl> <chr>  <lgl> <dbl>\n1 <NA>                                        NA    <NA>   NA       NA\n2 CANADA                                      NA    <NA>   NA      662\n3 <NA>                                        NA    <NA>   NA       NA\n4 1  Military designation.                    NA    <NA>   NA       NA\n5 <NA>                                        NA    <NA>   NA       NA\n6 NOTE:  Excludes 2,896 employees without an… NA    <NA>   NA       NA\n\nThis needs further cleaning to make it suitable for further analysis.\n\n\nState_county <- select(State_county, -c(2, 4))\nState_county <- State_county[complete.cases(State_county),]\nhead(State_county)\n\n\n# A tibble: 6 × 3\n  STATE COUNTY               TOTAL\n  <chr> <chr>                <dbl>\n1 AE    APO                      2\n2 AK    ANCHORAGE                7\n3 AK    FAIRBANKS NORTH STAR     2\n4 AK    JUNEAU                   3\n5 AK    MATANUSKA-SUSITNA        2\n6 AK    SITKA                    1\n\ntail(State_county)\n\n\n# A tibble: 6 × 3\n  STATE COUNTY     TOTAL\n  <chr> <chr>      <dbl>\n1 WY    SHERIDAN     252\n2 WY    SUBLETTE       3\n3 WY    SWEETWATER   196\n4 WY    UINTA         49\n5 WY    WASHAKIE      10\n6 WY    WESTON        37\n\nThis looks much better!\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:47-04:00",
    "input_file": "railroad-employment-data.knit.md"
  },
  {
    "path": "posts/2021-08-17-dn-australian-data/",
    "title": "DN Australian Data",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Dana Nestor",
        "url": {}
      }
    ],
    "date": "2021-08-17",
    "categories": [],
    "contents": "\nImporting data using a specific range to isolate desired variables, renaming variables to add meaningful values and allow for easier selecting, removing interstitial undesirable variables\n\n\nbase_marriage_data <- read_excel(\"../../_data/australian_marriage_law_postal_survey_2017_-_response_final.xls\", \n         sheet = \"Table 2\", \n         range = \"A8:P179\", \n         col_names = c(\"Town\", \"Yes\", \"d\", \"No\", rep(\"d\", 6), \"Not Clear\", \"d\", \n                       \"No Response\", rep(\"d\", 3)))%>%\n  select(!starts_with(\"d\"))\n\n\n\nThe next variable we need to isolate is County which, in this data set, has a parent-child relationship with Town. To accomplish this, we will create a new column for County values that correlate with their child towns and order the columns in descending complexity (in this case, county then town)\n\n\nbase_marriage_data <- base_marriage_data%>%\n  mutate(County = case_when(\n    str_ends(Town, \"Divisions\") ~ Town, \n    TRUE ~ NA_character_))%>%\n# Because I cannot get the .before or .after arguments to work with mutate(), I am using the relocate() function to move the County column before the Town column so we can maintain a descending order of complexity in governmental organizations\n  relocate(County, .before = Town)\n\n\n\nTo complete the isolation of County data, we need to populate our new column with the appropriate parent-county for their associated child-towns. We use a loop function to pull the County value down our column, stopping when a new county is reached and then restarting itself with the new county value.\n\n\ntidy_marriage_data <- base_marriage_data\nfor(i in seq_along(tidy_marriage_data$County)) {tidy_marriage_data$County[i] <- ifelse(is.na(tidy_marriage_data$County[i]), tidy_marriage_data$County[i-1], tidy_marriage_data$County[i])}\n\n\n\nThis next chunk removes undesirable rows so we can isolate our observations. Since we were able to import our data with a range that cut out unnecessary rows above and below our data frame, now we need to account for interstitial rows without data and rows with totals\n\n\ntidier_marriage_data <- tidy_marriage_data%>%drop_na(Town, Yes)%>%\n  filter(!str_detect(Town, \"(Total)\"))\n\n\n\nAs an extra step to tidy the data, we can remove “Divisions” in the County column as this variable is now describing the county itself, not the child-towns.\n\n\ntidiest_marriage_data <- mutate(tidier_marriage_data, County = str_remove(County, \" Divisions\"))%>%\n  mutate(Town = str_remove(Town, \"\\\\([cde]\\\\)\"))\n  view(tidiest_marriage_data)\n\n\n\nNOTE tidy objects, condense code (under 15 lines?)\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:49-04:00",
    "input_file": "dn-australian-data.knit.md"
  },
  {
    "path": "posts/2021-08-17-noahhw3/",
    "title": "NoahHw3",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Noah Milstein",
        "url": {}
      }
    ],
    "date": "2021-08-17",
    "categories": [],
    "contents": "\nChicken Data In the code below I am loading all of the packages I will be using throughout this assignment\n\n\nlibrary(tidyverse) \nlibrary(dplyr) \nlibrary(knitr) \nlibrary(readxl) \nlibrary(ggplot2) \nlibrary(broom) \n\n\n\nThe code below is my file path for importing the data regarding chicken meat prices in excel form\n\n\npoultry <- read_excel(\"../../_data/poultry_tidy.xlsx\") \n\n\n\nThe Poultry The Poultry data is broken into 4 columns, Product which is the cut of chicken, Year and Month corresponding to each observation. Price_Dollar represents the price of each cut at a month and year.\n\n\npoultry \n\n\n# A tibble: 600 × 4\n   Product  Year Month     Price_Dollar\n   <chr>   <dbl> <chr>            <dbl>\n 1 Whole    2013 January           2.38\n 2 Whole    2013 February          2.38\n 3 Whole    2013 March             2.38\n 4 Whole    2013 April             2.38\n 5 Whole    2013 May               2.38\n 6 Whole    2013 June              2.38\n 7 Whole    2013 July              2.38\n 8 Whole    2013 August            2.38\n 9 Whole    2013 September         2.38\n10 Whole    2013 October           2.38\n# … with 590 more rows\n\nBelow is my initial data table manipulation which I did to get a specific product, in this case boneless breast with its price and the year in which that price was observed\n\n\npoultry %>% group_by(`Price_Dollar`)%>% \n  \n# first line groups the data by the price in the \n#Price_Dollar column so the data in the column is sorted into chunks of the same price. \n  \nselect(!(`Month`))%>% \n  \n# This select function selects all columns except for the one called \"Month\" \n  \nfilter(Product==\"B/S Breast\") %>% \n  \n# The line above selects only the Product in the \n#\"Product\" column called \"B/S Breast, or boneless chicken breast\" \n  \narrange(desc(`Price_Dollar`)) %>% \n\n# The above line sorts or arranges the column of \n# Price in dollars or \"Price_Dollar\" in descending order \n#starting above 7 dollars and going down closer to 6 dollars \nrename(Chicken_Bonless_Breast_Price=Price_Dollar)\n\n\n# A tibble: 120 × 3\n# Groups:   Chicken_Bonless_Breast_Price [8]\n   Product     Year Chicken_Bonless_Breast_Price\n   <chr>      <dbl>                        <dbl>\n 1 B/S Breast  2013                         7.04\n 2 B/S Breast  2013                         7.04\n 3 B/S Breast  2013                         7.04\n 4 B/S Breast  2013                         7.04\n 5 B/S Breast  2013                         7.04\n 6 B/S Breast  2013                         7.04\n 7 B/S Breast  2013                         7.04\n 8 B/S Breast  2013                         7.04\n 9 B/S Breast  2013                         7.04\n10 B/S Breast  2013                         7.04\n# … with 110 more rows\n\n# This above line renames the column \n#\"Price_Dollar\" into column \"Chicken_Boneless_Breast_Price\" \n# The line above takes the poultry data frame, it then finds the mean price in dollars and removes all N/A observations \n\n\n\n\n\nsummarise(poultry, mean(`Price_Dollar`, na.rm = TRUE)) \n\n\n# A tibble: 1 × 1\n  `mean(Price_Dollar, na.rm = TRUE)`\n                               <dbl>\n1                               3.39\n\nThe first line groups the data by the price in the Price_Dollar column so the data in the column is sorted into chunks of the same price.\nThe second line selects all columns except for the one called “Month”\nThe third line selects only the Product in the “Product” column called “B/S Breast, or boneless chicken breast”\nThe fourth line sorts or arranges the column of Price in dollars or “Price_Dollar” in descending order starting above 7 dollars and going down closer to 6 dollars This fifth line renames the column “Price_Dollar” into column “Chicken_Boneless_Breast_Price”\nThe final line of codes above takes the poultry data frame, it then finds the mean price in dollars and removes all N/A observations\n\n\npoultry %>% group_by(Year, Price_Dollar, Product) %>% ggplot() + geom_smooth(mapping=aes(y=Price_Dollar, x=Year, color=Product), na.rm=TRUE) \n\n\n\n\nPoultry Plot Post and Conclusion\nBy Noah Milstein\nChicken Data Conclusion\nThe graph above suggests that the price of most chicken cuts remain relatively similar over time, however B/S Breast or boneless chicken breast appears to have increased in price over recent years. Thighs have also remained relatively similar\n\n\n\n",
    "preview": "posts/2021-08-17-noahhw3/noahhw3_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2021-08-18T15:30:57-04:00",
    "input_file": "noahhw3.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-17-railroad-county-tracy/",
    "title": "RAILROAD-COUNTY-TRACY",
    "description": "**HOMEWORK 2**\n\n**Data breaking down US railroad employment numbers in 2012 by state and county. Data includes three variables: state, county and total employees. 2930 observations. Total number of employees ranges from 1 to over 3000. Specifically analyzing two subsets of data: large railroads (1000+ employees) and separately railroads in New England.**",
    "author": [
      {
        "name": "Erin-Tracy",
        "url": {}
      }
    ],
    "date": "2021-08-17",
    "categories": [],
    "contents": "\n#QUESTION- WHY WON’T SOURCE URL APPEAR IN DESCRIPTION?\n#For now, Echo is TRUE, may want to go back later and change to FALSE\n\n\nknitr::opts_chunk$set(echo = TRUE)\n\nlibrary(\"tidyverse\")\nlibrary(\"readr\")\nlibrary(\"ggplot2\")\nlibrary(\"dplyr\")\nknitr::opts_chunk$set(fig.width = 5, fig.asp = 1/3)\n\n\n\n#HOMEWORK 1 # Here I am reading in my CSV file.\n\n\ndata<-read.csv(\"../../_data/railroad_2012_clean_county.csv\")\n\n#Head\nhead(data)\n\n\n  state               county total_employees\n1    AE                  APO               2\n2    AK            ANCHORAGE               7\n3    AK FAIRBANKS NORTH STAR               2\n4    AK               JUNEAU               3\n5    AK    MATANUSKA-SUSITNA               2\n6    AK                SITKA               1\n\n#Tail\ntail(data)\n\n\n     state     county total_employees\n2925    WY   SHERIDAN             252\n2926    WY   SUBLETTE               3\n2927    WY SWEETWATER             196\n2928    WY      UINTA              49\n2929    WY   WASHAKIE              10\n2930    WY     WESTON              37\n\n#Dimensions\ndim(data)\n\n\n[1] 2930    3\n\n#Column Names\ncolnames(data)\n\n\n[1] \"state\"           \"county\"          \"total_employees\"\n\n#HOMEWORK 3: Experimenting with Data Transformation #Specifically determining average number of railroad employees with Summarise, count of railroads per state and average number of railroad employees by state.\n\n#Average of Railroad Employees for complete dataset\nsummarise(data,avg=mean(total_employees))\n\n\n       avg\n1 87.17816\n\n#Count of Railroads by State\ncount(data,state)\n\n\n   state   n\n1     AE   1\n2     AK   6\n3     AL  67\n4     AP   1\n5     AR  72\n6     AZ  15\n7     CA  55\n8     CO  57\n9     CT   8\n10    DC   1\n11    DE   3\n12    FL  67\n13    GA 152\n14    HI   3\n15    IA  99\n16    ID  36\n17    IL 103\n18    IN  92\n19    KS  95\n20    KY 119\n21    LA  63\n22    MA  12\n23    MD  24\n24    ME  16\n25    MI  78\n26    MN  86\n27    MO 115\n28    MS  78\n29    MT  53\n30    NC  94\n31    ND  49\n32    NE  89\n33    NH  10\n34    NJ  21\n35    NM  29\n36    NV  12\n37    NY  61\n38    OH  88\n39    OK  73\n40    OR  33\n41    PA  65\n42    RI   5\n43    SC  46\n44    SD  52\n45    TN  91\n46    TX 221\n47    UT  25\n48    VA  92\n49    VT  14\n50    WA  39\n51    WI  69\n52    WV  53\n53    WY  22\n\n#Average of Employees per Railroad in each State\ndata %>%\n  group_by(state) %>%\n  summarise(avg=mean(total_employees))\n\n\n# A tibble: 53 × 2\n   state   avg\n   <chr> <dbl>\n 1 AE      2  \n 2 AK     17.2\n 3 AL     63.5\n 4 AP      1  \n 5 AR     53.8\n 6 AZ    210. \n 7 CA    239. \n 8 CO     64.0\n 9 CT    324  \n10 DC    279  \n# … with 43 more rows\n\n#Experimenting with prop.table\n\n\n#Percentage of Railroads by State\n#Confirm I understand this correctly\ndata%>%\n  select(state)%>%\n  table()%>%\n  prop.table()*100\n\n\n.\n        AE         AK         AL         AP         AR         AZ \n0.03412969 0.20477816 2.28668942 0.03412969 2.45733788 0.51194539 \n        CA         CO         CT         DC         DE         FL \n1.87713311 1.94539249 0.27303754 0.03412969 0.10238908 2.28668942 \n        GA         HI         IA         ID         IL         IN \n5.18771331 0.10238908 3.37883959 1.22866894 3.51535836 3.13993174 \n        KS         KY         LA         MA         MD         ME \n3.24232082 4.06143345 2.15017065 0.40955631 0.81911263 0.54607509 \n        MI         MN         MO         MS         MT         NC \n2.66211604 2.93515358 3.92491468 2.66211604 1.80887372 3.20819113 \n        ND         NE         NH         NJ         NM         NV \n1.67235495 3.03754266 0.34129693 0.71672355 0.98976109 0.40955631 \n        NY         OH         OK         OR         PA         RI \n2.08191126 3.00341297 2.49146758 1.12627986 2.21843003 0.17064846 \n        SC         SD         TN         TX         UT         VA \n1.56996587 1.77474403 3.10580205 7.54266212 0.85324232 3.13993174 \n        VT         WA         WI         WV         WY \n0.47781570 1.33105802 2.35494881 1.80887372 0.75085324 \n\n#HOMEWORK 3: Experimenting with Filter and Arrange #Specifically pulling only railroads with 1000+ employees, naming that group “Large Railroads”\n\n\n#Filter out large railroads\nfilter(data,total_employees>=1000)\n\n\n   state           county total_employees\n1     CA      LOS ANGELES            2545\n2     CA        RIVERSIDE            1567\n3     CA   SAN BERNARDINO            2888\n4     CT        NEW HAVEN            1561\n5     DE       NEW CASTLE            1275\n6     FL            DUVAL            3073\n7     IL             COOK            8207\n8     IL             WILL            1784\n9     IN             LAKE            1999\n10    KS          JOHNSON            1286\n11    MO          JACKSON            2055\n12    NE        BOX BUTTE            1168\n13    NE          DOUGLAS            3797\n14    NE        LANCASTER            1619\n15    NE          LINCOLN            2289\n16    NJ            ESSEX            1097\n17    NY         DUTCHESS            1157\n18    NY           NASSAU            2076\n19    NY           QUEENS            1470\n20    NY          SUFFOLK            3685\n21    NY      WESTCHESTER            1040\n22    PA            BUCKS            1106\n23    PA     PHILADELPHIA            1649\n24    TX           HARRIS            2535\n25    TX          TARRANT            4235\n26    VA INDEPENDENT CITY            3249\n27    WA             KING            1039\n\n#Reassign large railroads\nlarge_railroads<- filter(data,total_employees>=1000)\n\n#Head\nhead(large_railroads)\n\n\n  state         county total_employees\n1    CA    LOS ANGELES            2545\n2    CA      RIVERSIDE            1567\n3    CA SAN BERNARDINO            2888\n4    CT      NEW HAVEN            1561\n5    DE     NEW CASTLE            1275\n6    FL          DUVAL            3073\n\n#Count\ncount(large_railroads)\n\n\n   n\n1 27\n\n#Arrange by Total Employees \narrange(large_railroads, desc(total_employees), state, county)\n\n\n   state           county total_employees\n1     IL             COOK            8207\n2     TX          TARRANT            4235\n3     NE          DOUGLAS            3797\n4     NY          SUFFOLK            3685\n5     VA INDEPENDENT CITY            3249\n6     FL            DUVAL            3073\n7     CA   SAN BERNARDINO            2888\n8     CA      LOS ANGELES            2545\n9     TX           HARRIS            2535\n10    NE          LINCOLN            2289\n11    NY           NASSAU            2076\n12    MO          JACKSON            2055\n13    IN             LAKE            1999\n14    IL             WILL            1784\n15    PA     PHILADELPHIA            1649\n16    NE        LANCASTER            1619\n17    CA        RIVERSIDE            1567\n18    CT        NEW HAVEN            1561\n19    NY           QUEENS            1470\n20    KS          JOHNSON            1286\n21    DE       NEW CASTLE            1275\n22    NE        BOX BUTTE            1168\n23    NY         DUTCHESS            1157\n24    PA            BUCKS            1106\n25    NJ            ESSEX            1097\n26    NY      WESTCHESTER            1040\n27    WA             KING            1039\n\n#HOMEWORK 3: Experimenting with Select\n\n\n#Large Railroads (1000+ employees)are located in these counties/states\nselect(large_railroads,\"state\", \"county\")\n\n\n   state           county\n1     CA      LOS ANGELES\n2     CA        RIVERSIDE\n3     CA   SAN BERNARDINO\n4     CT        NEW HAVEN\n5     DE       NEW CASTLE\n6     FL            DUVAL\n7     IL             COOK\n8     IL             WILL\n9     IN             LAKE\n10    KS          JOHNSON\n11    MO          JACKSON\n12    NE        BOX BUTTE\n13    NE          DOUGLAS\n14    NE        LANCASTER\n15    NE          LINCOLN\n16    NJ            ESSEX\n17    NY         DUTCHESS\n18    NY           NASSAU\n19    NY           QUEENS\n20    NY          SUFFOLK\n21    NY      WESTCHESTER\n22    PA            BUCKS\n23    PA     PHILADELPHIA\n24    TX           HARRIS\n25    TX          TARRANT\n26    VA INDEPENDENT CITY\n27    WA             KING\n\n#HOMEWORK 3: Experimenting with Filter, Vector, Piping, and Group by\n\n\n#Created subset of data that is just New England states, rename that group \"new_england\"\nnew_england <- filter(data, state %in% c(\"NH\", \"VT\", \"CT\", \"MA\", \"RI\", \"ME\"))\n\n#Average number of employees per railroad based on New England States only\nsummarise(new_england, avg=mean(total_employees))\n\n\n       avg\n1 119.4462\n\n#Count of railroads by state and then by county for New England States only\ncount(new_england,state)\n\n\n  state  n\n1    CT  8\n2    MA 12\n3    ME 16\n4    NH 10\n5    RI  5\n6    VT 14\n\ncount(new_england,county)\n\n\n         county n\n1       ADDISON 1\n2  ANDROSCOGGIN 1\n3     AROOSTOOK 1\n4    BARNSTABLE 1\n5       BELKNAP 1\n6    BENNINGTON 1\n7     BERKSHIRE 1\n8       BRISTOL 2\n9     CALEDONIA 1\n10      CARROLL 1\n11     CHESHIRE 1\n12   CHITTENDEN 1\n13         COOS 1\n14   CUMBERLAND 1\n15        ESSEX 2\n16    FAIRFIELD 1\n17     FRANKLIN 3\n18      GRAFTON 1\n19   GRAND ISLE 1\n20      HAMPDEN 1\n21    HAMPSHIRE 1\n22      HANCOCK 1\n23     HARTFORD 1\n24 HILLSBOROUGH 1\n25     KENNEBEC 1\n26         KENT 1\n27         KNOX 1\n28     LAMOILLE 1\n29      LINCOLN 1\n30   LITCHFIELD 1\n31    MERRIMACK 1\n32    MIDDLESEX 2\n33    NEW HAVEN 1\n34   NEW LONDON 1\n35      NEWPORT 1\n36      NORFOLK 1\n37       ORANGE 1\n38      ORLEANS 1\n39       OXFORD 1\n40    PENOBSCOT 1\n41  PISCATAQUIS 1\n42     PLYMOUTH 1\n43   PROVIDENCE 1\n44   ROCKINGHAM 1\n45      RUTLAND 1\n46    SAGADAHOC 1\n47     SOMERSET 1\n48    STRAFFORD 1\n49      SUFFOLK 1\n50     SULLIVAN 1\n51      TOLLAND 1\n52        WALDO 1\n53   WASHINGTON 3\n54      WINDHAM 2\n55      WINDSOR 1\n56    WORCESTER 1\n57         YORK 1\n\n#Average number of employees per railroad per state\nnew_england %>%\n  group_by(state) %>%\n  summarise(avg=mean(total_employees))\n\n\n# A tibble: 6 × 2\n  state   avg\n  <chr> <dbl>\n1 CT    324  \n2 MA    282. \n3 ME     40.9\n4 NH     39.3\n5 RI     97.4\n6 VT     18.5\n\n#Experimenting with Crosstabs\n\n\n#This is not pretty, I'd like to revisit using ranges\nxtabs(~total_employees + state,new_england)\n\n\n               state\ntotal_employees CT MA ME NH RI VT\n           2     0  0  1  1  0  0\n           3     0  0  1  0  0  2\n           4     0  0  0  0  0  2\n           5     0  0  1  0  0  1\n           7     0  0  1  2  0  0\n           8     0  0  1  0  1  2\n           9     0  0  0  1  0  1\n           10    0  0  0  0  0  2\n           11    0  0  1  0  1  0\n           12    0  0  0  1  0  0\n           13    0  0  0  0  0  1\n           17    0  0  1  0  0  0\n           19    0  0  0  1  0  0\n           22    0  0  1  0  0  0\n           26    1  0  0  0  0  0\n           27    0  0  0  1  0  0\n           28    0  0  0  1  0  0\n           36    0  0  1  0  0  0\n           40    0  0  0  0  0  1\n           44    0  1  0  0  0  0\n           47    0  0  1  0  0  0\n           48    0  0  0  0  1  0\n           50    0  1  0  0  0  0\n           57    1  0  1  0  0  0\n           59    0  0  0  0  0  1\n           66    1  0  0  0  0  0\n           67    0  0  1  0  0  0\n           68    0  1  0  0  0  0\n           71    0  0  1  0  0  0\n           75    0  0  1  0  0  0\n           83    0  0  0  0  0  1\n           102   0  0  0  0  1  0\n           109   0  0  1  0  0  0\n           113   1  1  0  0  0  0\n           117   0  0  1  0  0  0\n           136   0  0  0  1  0  0\n           137   1  0  0  0  0  0\n           146   1  0  0  1  0  0\n           202   0  1  0  0  0  0\n           232   0  1  0  0  0  0\n           310   0  1  0  0  0  0\n           314   0  1  0  0  0  0\n           318   0  0  0  0  1  0\n           386   0  1  0  0  0  0\n           429   0  1  0  0  0  0\n           486   1  0  0  0  0  0\n           558   0  1  0  0  0  0\n           673   0  1  0  0  0  0\n           1561  1  0  0  0  0  0\n\n#Experimenting with ggplot, boxplot, WORK ON THIS SOME MORE! NEED LABELS\n\n\n#Boxplot for New England States\nggplot(new_england,aes(state,total_employees))+geom_boxplot()\n\n\n\n\n#Experimenting with ggplot, geom_point, WORK ON THIS SOME MORE!\n\n\n#Geompoints for New England States\nggplot(new_england,aes(state,total_employees))+\n  geom_point()+\n  geom_smooth()+\n  labs(title = \"Railroad Employee Counts by State\", y = \"Total Employees\", x = \"State\") \n\n\n\n#Unfinished\n#ggplot(data=new_england)+\n  #geom_point(mapping=aes(x=county, y=total_employees))+\n\n\n\n#Experimenting with ggplot and fill #QUESTION- CAN I MAKE KEY SMALLER AND GRAPH LARGER?\n\n\n#Geomplot for New England States with County filled (Two Ways)\n#ggplot(new_england,aes(state, fill=county))+ geom_bar()+\n  #theme_bw()+\n  #labs(title=\"New England States Railroad Employee Counts by State and County\", y=\"Number of Employees\", x= \"State\")\n\n#ggplot(data=new_england)+\n  #geom_bar(mapping=aes(x=state, fill=county))\n  #theme_bw()+\n  #labs(title=\"New England States Railroad Employee Counts by State and County\", y=\"Number of Employees\", x= \"State\")\n\n#Removed Code, Very Messy for Now\n\n\n\n#Experimenting with geompoint, with different dataset\n\n\nggplot(data=large_railroads)+\n  geom_point(mapping=aes(x=state, y=total_employees))+\n  labs(title = \"Railroads with 1000+ Employees\", y = \"Total Employees\", x = \"State\") \n\n\n\n\n#Experimenting with Advanced Functions for HW3\n\n\n#rename()\n\n#case_when()\n\n#relocate()\n\n#across()/c_across()\n\n#pivot_longer()/pivot_wider()\n\n#purrr::map()\n\n#lapply()\n\n\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": "posts/2021-08-17-railroad-county-tracy/railroad-county-tracy_files/figure-html5/unnamed-chunk-8-1.png",
    "last_modified": "2021-08-18T15:31:00-04:00",
    "input_file": "railroad-county-tracy.knit.md",
    "preview_width": 960,
    "preview_height": 320
  },
  {
    "path": "posts/2021-08-17-hw02/",
    "title": "HW02",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "TMoraitis",
        "url": {}
      }
    ],
    "date": "2021-08-17",
    "categories": [],
    "contents": "\n\n\n#Loading Library\nlibrary(tidyverse)\n\n\n\n##Data\n\n\npoultry <- read_csv(file=\"../../_data/poultry_tidy.csv\")\nhead(poultry)\n\n\n# A tibble: 6 × 4\n  Product  Year Month    Price_Dollar\n  <chr>   <dbl> <chr>           <dbl>\n1 Whole    2013 January          2.38\n2 Whole    2013 February         2.38\n3 Whole    2013 March            2.38\n4 Whole    2013 April            2.38\n5 Whole    2013 May              2.38\n6 Whole    2013 June             2.38\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:51-04:00",
    "input_file": "hw02.knit.md"
  },
  {
    "path": "posts/2021-08-17-hw03/",
    "title": "HW03",
    "description": "This is my submission of HW3",
    "author": [],
    "date": "2021-08-17",
    "categories": [],
    "contents": "\n\n\n#Loading Library\nlibrary(tidyverse)\n\n\n\n\n\n# Reading file\nhotelBookings <- read_csv(file=\"../../_data/hotel_bookings.csv\") \n\n#Using required functions\nhotelBookings %>%\n  select(1:4) %>%\n  filter(arrival_date_year==2015) %>%\n  arrange(4)\n\n\n# A tibble: 21,996 × 4\n   hotel        is_canceled lead_time arrival_date_year\n   <chr>              <dbl>     <dbl>             <dbl>\n 1 Resort Hotel           0       342              2015\n 2 Resort Hotel           0       737              2015\n 3 Resort Hotel           0         7              2015\n 4 Resort Hotel           0        13              2015\n 5 Resort Hotel           0        14              2015\n 6 Resort Hotel           0        14              2015\n 7 Resort Hotel           0         0              2015\n 8 Resort Hotel           0         9              2015\n 9 Resort Hotel           1        85              2015\n10 Resort Hotel           1        75              2015\n# … with 21,986 more rows\n\nhotelBookings %>%\n  group_by(hotel) %>%\n  summarise(mean = mean(adr), n = n())\n\n\n# A tibble: 2 × 3\n  hotel         mean     n\n  <chr>        <dbl> <int>\n1 City Hotel   105.  79330\n2 Resort Hotel  95.0 40060\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:54-04:00",
    "input_file": "hw03.knit.md"
  },
  {
    "path": "posts/2021-08-17-example-code-for-pivot-longer/",
    "title": "Example Code for Pivot Longer",
    "description": "I'm sharing some example code for pivot_longer using the eggs data. Enjoy!",
    "author": [
      {
        "name": "Meredith Rolfe",
        "url": {}
      }
    ],
    "date": "2021-08-17",
    "categories": [],
    "contents": "\nThis is example code for using the pivot functions in R. Several of the government data sources include tabular data that really need to be pivoted into a dataset in which a “case” is some combination of the grouping variables (the rows and columns in the table) alongside the appropriate statistical value(s) in the table (e.g., counts or average costs). Lets start with the easy to read in eggs_tidy.csv just so we can focus on the pivoting function.\n\n\neggs<-read_csv(\"../../_data/eggs_tidy.csv\", show_col_types = FALSE)\neggs\n\n\n# A tibble: 120 × 6\n   month      year large_half_dozen large_dozen extra_large_half_dozen\n   <chr>     <dbl>            <dbl>       <dbl>                  <dbl>\n 1 January    2004             126         230                    132 \n 2 February   2004             128.        226.                   134.\n 3 March      2004             131         225                    137 \n 4 April      2004             131         225                    137 \n 5 May        2004             131         225                    137 \n 6 June       2004             134.        231.                   137 \n 7 July       2004             134.        234.                   137 \n 8 August     2004             134.        234.                   137 \n 9 September  2004             130.        234.                   136.\n10 October    2004             128.        234.                   136.\n# … with 110 more rows, and 1 more variable: extra_large_dozen <dbl>\n\nLooking at the data, we can see that each case consists of a year-month combination (e.g., January 2004), while the values are the average price (in cents) of four different types of eggs (e.g., large_half_dozen, large_dozen, etc) But really, wouldn’t it possibly make more sense to consider the case as a year-month-type combination, with a single price value for each case?\nPivot Longer - One Bew Category Variable\nTo do this (and make our data easier to graph and analyze), we can pivot longer - changing our data from 120 rows with 6 variables (2 grouping and 4 values) to 480 rows of 4 variables (with 3 grouping variables and a single price value).\n\n\neggs%>%\n  pivot_longer(cols=large_half_dozen:extra_large_dozen, \n               names_to = \"eggType\",\n               values_to = \"avgPrice\"\n  )\n\n\n# A tibble: 480 × 4\n   month     year eggType                avgPrice\n   <chr>    <dbl> <chr>                     <dbl>\n 1 January   2004 large_half_dozen           126 \n 2 January   2004 large_dozen                230 \n 3 January   2004 extra_large_half_dozen     132 \n 4 January   2004 extra_large_dozen          230 \n 5 February  2004 large_half_dozen           128.\n 6 February  2004 large_dozen                226.\n 7 February  2004 extra_large_half_dozen     134.\n 8 February  2004 extra_large_dozen          230 \n 9 March     2004 large_half_dozen           131 \n10 March     2004 large_dozen                225 \n# … with 470 more rows\n\nWell, that was super easy. But wait, what if you are interested in egg size - you want to know how much more expensive extra-large eggs are compared to large eggs. Right now, that will be annoying, as you will have to keep sorting out the egg quantity - whether the price is for a half_dozen or a dozen eggs. Wouldn’t it be nice if we didn’t have a long egg type column with both size and quantity squashed into a single categorical variable? It would be so useful to have a new dataset with 4 grouping variables (year, month, size, and quantity) and the same value (price).\nPivot Longer - Two New Category Variables\nSo, once again we want to use pivot longer, but we will be adding two new category variables (for a total of 4) and this will cut the number of rows in half (to 240). But how in the world can we let R know what we want it to do?? Thankfully, someone named the egg types (column-names) pretty systematically, but how can use this to our advantage? Working with patterns in the names_sep option of the pivot functions makes it pretty easy (well, except our variable names have more than one underscore, so we have to sort of hack this part by also using mutate on the resulting category labels.)\n\n\neggs%>%\n  pivot_longer(cols=large_half_dozen:extra_large_dozen,\n               names_to = c(\"size\", \"quantity\"),\n               names_sep=\"arge_\",\n               values_to = \"price\"\n  ) %>%\n  mutate(size = case_when(\n    size == \"l\" ~ \"Large\",\n    size == \"extra_l\" ~ \"Extra Large\"\n  ))\n\n\n# A tibble: 480 × 5\n   month     year size        quantity   price\n   <chr>    <dbl> <chr>       <chr>      <dbl>\n 1 January   2004 Large       half_dozen  126 \n 2 January   2004 Large       dozen       230 \n 3 January   2004 Extra Large half_dozen  132 \n 4 January   2004 Extra Large dozen       230 \n 5 February  2004 Large       half_dozen  128.\n 6 February  2004 Large       dozen       226.\n 7 February  2004 Extra Large half_dozen  134.\n 8 February  2004 Extra Large dozen       230 \n 9 March     2004 Large       half_dozen  131 \n10 March     2004 Large       dozen       225 \n# … with 470 more rows\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:50-04:00",
    "input_file": "example-code-for-pivot-longer-railroad.knit.md"
  },
  {
    "path": "posts/2021-08-16-hanae-homework-3/",
    "title": "Hanae- Homework 3",
    "description": "This is my submission of Homework 3.",
    "author": [
      {
        "name": "Hanae Bouazza",
        "url": {}
      }
    ],
    "date": "2021-08-16",
    "categories": [],
    "contents": "\n##Loading Library\n\n\nlibrary(tidyverse)\n\n\n\n##Data\n\n\nbookings<-read_csv(file=\"../../_data/hotel_bookings.csv\")\n\n\n\n##Using summarise() and group_by()\n\n\ngroup_by(bookings, hotel)%>%\nsummarise(meanAdr=mean(adr), n=n())\n\n\n# A tibble: 2 × 3\n  hotel        meanAdr     n\n  <chr>          <dbl> <int>\n1 City Hotel     105.  79330\n2 Resort Hotel    95.0 40060\n\n##Using arrange(), select(), and filter()\n\n\nstatusByCountry<-arrange(bookings, reservation_status)%>%\nselect(\"hotel\", \"country\", \"reservation_status\")\nfilter(statusByCountry, country==\"USA\")\n\n\n# A tibble: 2,097 × 3\n   hotel        country reservation_status\n   <chr>        <chr>   <chr>             \n 1 Resort Hotel USA     Canceled          \n 2 Resort Hotel USA     Canceled          \n 3 Resort Hotel USA     Canceled          \n 4 Resort Hotel USA     Canceled          \n 5 Resort Hotel USA     Canceled          \n 6 Resort Hotel USA     Canceled          \n 7 Resort Hotel USA     Canceled          \n 8 Resort Hotel USA     Canceled          \n 9 Resort Hotel USA     Canceled          \n10 Resort Hotel USA     Canceled          \n# … with 2,087 more rows\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:45-04:00",
    "input_file": "hanae-homework-3.knit.md"
  },
  {
    "path": "posts/2021-08-15-zoe-hotel-bookings-dataset/",
    "title": "Zoe Hotel Bookings Dataset",
    "description": "An introdution to the hotel dataset",
    "author": [
      {
        "name": "Zoe Bean",
        "url": {}
      }
    ],
    "date": "2021-08-15",
    "categories": [],
    "contents": "\nHomework 2\nI will be processing a dataset about hotel bookings from 2015 to 2017. First, I import the dataset, which requires the tidyverse package to be loaded.\n\n\nlibrary(tidyverse)\nhotel_data=read_csv(\"../../_data/hotel_bookings.csv\")\n\n\n\nNext, I use head() to give an example of what the dataset looks like.\n\n\nhead(hotel_data)\n\n\n# A tibble: 6 × 32\n  hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n  <chr>              <dbl>     <dbl>            <dbl> <chr>           \n1 Resort Hotel           0       342             2015 July            \n2 Resort Hotel           0       737             2015 July            \n3 Resort Hotel           0         7             2015 July            \n4 Resort Hotel           0        13             2015 July            \n5 Resort Hotel           0        14             2015 July            \n6 Resort Hotel           0        14             2015 July            \n# … with 27 more variables: arrival_date_week_number <dbl>,\n#   arrival_date_day_of_month <dbl>, stays_in_weekend_nights <dbl>,\n#   stays_in_week_nights <dbl>, adults <dbl>, children <dbl>,\n#   babies <dbl>, meal <chr>, country <chr>, market_segment <chr>,\n#   distribution_channel <chr>, is_repeated_guest <dbl>,\n#   previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\nTo find out how many rows are in the dataset, I use dim(). I also use colnames() to figure out what the data drawn from each observation are.\n\n\ndim(hotel_data)\n\n\n[1] 119390     32\n\ncolnames(hotel_data)\n\n\n [1] \"hotel\"                          \"is_canceled\"                   \n [3] \"lead_time\"                      \"arrival_date_year\"             \n [5] \"arrival_date_month\"             \"arrival_date_week_number\"      \n [7] \"arrival_date_day_of_month\"      \"stays_in_weekend_nights\"       \n [9] \"stays_in_week_nights\"           \"adults\"                        \n[11] \"children\"                       \"babies\"                        \n[13] \"meal\"                           \"country\"                       \n[15] \"market_segment\"                 \"distribution_channel\"          \n[17] \"is_repeated_guest\"              \"previous_cancellations\"        \n[19] \"previous_bookings_not_canceled\" \"reserved_room_type\"            \n[21] \"assigned_room_type\"             \"booking_changes\"               \n[23] \"deposit_type\"                   \"agent\"                         \n[25] \"company\"                        \"days_in_waiting_list\"          \n[27] \"customer_type\"                  \"adr\"                           \n[29] \"required_car_parking_spaces\"    \"total_of_special_requests\"     \n[31] \"reservation_status\"             \"reservation_status_date\"       \n\nThe result from dim() means that there are 119390 rows and 32 columns. This is important since the number of rows tells us how many hotel bookings there are in this dataset, and the columns tell us how many pieces of data are available per booking.\nHomework 3\nThe colnames function is helpful for this next step, where I select columns. Here, I select the year of arrival and the month.\n\n\nselect(hotel_data, arrival_date_year, arrival_date_month )\n\n\n# A tibble: 119,390 × 2\n   arrival_date_year arrival_date_month\n               <dbl> <chr>             \n 1              2015 July              \n 2              2015 July              \n 3              2015 July              \n 4              2015 July              \n 5              2015 July              \n 6              2015 July              \n 7              2015 July              \n 8              2015 July              \n 9              2015 July              \n10              2015 July              \n# … with 119,380 more rows\n\nI can do more with select, such as selecting all columns that start with ‘arrival_date’ to get more clear information about when each the booking is.\n\n\nselect(hotel_data, starts_with(\"arrival_date\"))\n\n\n# A tibble: 119,390 × 4\n   arrival_date_ye… arrival_date_mo… arrival_date_we… arrival_date_da…\n              <dbl> <chr>                       <dbl>            <dbl>\n 1             2015 July                           27                1\n 2             2015 July                           27                1\n 3             2015 July                           27                1\n 4             2015 July                           27                1\n 5             2015 July                           27                1\n 6             2015 July                           27                1\n 7             2015 July                           27                1\n 8             2015 July                           27                1\n 9             2015 July                           27                1\n10             2015 July                           27                1\n# … with 119,380 more rows\n\nIf I want to look at all the bookings where there are no children, I use filter() as follows:\n\n\nfilter(hotel_data, children== 0)\n\n\n# A tibble: 110,796 × 32\n   hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n   <chr>              <dbl>     <dbl>            <dbl> <chr>           \n 1 Resort Hotel           0       342             2015 July            \n 2 Resort Hotel           0       737             2015 July            \n 3 Resort Hotel           0         7             2015 July            \n 4 Resort Hotel           0        13             2015 July            \n 5 Resort Hotel           0        14             2015 July            \n 6 Resort Hotel           0        14             2015 July            \n 7 Resort Hotel           0         0             2015 July            \n 8 Resort Hotel           0         9             2015 July            \n 9 Resort Hotel           1        85             2015 July            \n10 Resort Hotel           1        75             2015 July            \n# … with 110,786 more rows, and 27 more variables:\n#   arrival_date_week_number <dbl>, arrival_date_day_of_month <dbl>,\n#   stays_in_weekend_nights <dbl>, stays_in_week_nights <dbl>,\n#   adults <dbl>, children <dbl>, babies <dbl>, meal <chr>,\n#   country <chr>, market_segment <chr>, distribution_channel <chr>,\n#   is_repeated_guest <dbl>, previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\nIf I want to arrange the hotel data by putting a column in order, I use arrange(). In this example, I order the data by the arrival month, which is sorted alphabetically.\n\n\narrange(hotel_data, arrival_date_month)\n\n\n# A tibble: 119,390 × 32\n   hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n   <chr>              <dbl>     <dbl>            <dbl> <chr>           \n 1 Resort Hotel           1        31             2016 April           \n 2 Resort Hotel           0         0             2016 April           \n 3 Resort Hotel           0       144             2016 April           \n 4 Resort Hotel           0       144             2016 April           \n 5 Resort Hotel           0       144             2016 April           \n 6 Resort Hotel           0       163             2016 April           \n 7 Resort Hotel           1        38             2016 April           \n 8 Resort Hotel           0       175             2016 April           \n 9 Resort Hotel           1        39             2016 April           \n10 Resort Hotel           1        32             2016 April           \n# … with 119,380 more rows, and 27 more variables:\n#   arrival_date_week_number <dbl>, arrival_date_day_of_month <dbl>,\n#   stays_in_weekend_nights <dbl>, stays_in_week_nights <dbl>,\n#   adults <dbl>, children <dbl>, babies <dbl>, meal <chr>,\n#   country <chr>, market_segment <chr>, distribution_channel <chr>,\n#   is_repeated_guest <dbl>, previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\nIf I actually wanted to have the months in order, I would have to make a numerical variable in the dataset using mutate() and case_when() and then arrange by that variable.\n\n\nhotel_data<- hotel_data %>%\n  mutate(arrival_date_month_num = case_when(\n         arrival_date_month == \"January\" ~ 1,\n         arrival_date_month == \"February\" ~ 2,\n         arrival_date_month == \"March\" ~ 3,\n         arrival_date_month == \"April\" ~ 4,\n         arrival_date_month == \"May\" ~ 5,\n         arrival_date_month == \"June\" ~ 6,\n         arrival_date_month == \"July\" ~ 7,\n         arrival_date_month == \"August\" ~ 8,\n         arrival_date_month == \"September\" ~ 9,\n         arrival_date_month == \"October\" ~ 10,\n         arrival_date_month == \"November\" ~ 11,\n         arrival_date_month == \"December\" ~ 12\n         ))\n\narrange(hotel_data, arrival_date_month_num)\n\n\n# A tibble: 119,390 × 33\n   hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n   <chr>              <dbl>     <dbl>            <dbl> <chr>           \n 1 Resort Hotel           0       109             2016 January         \n 2 Resort Hotel           0       109             2016 January         \n 3 Resort Hotel           1         2             2016 January         \n 4 Resort Hotel           0        88             2016 January         \n 5 Resort Hotel           1        20             2016 January         \n 6 Resort Hotel           1        76             2016 January         \n 7 Resort Hotel           0        88             2016 January         \n 8 Resort Hotel           1       113             2016 January         \n 9 Resort Hotel           1       113             2016 January         \n10 Resort Hotel           1       113             2016 January         \n# … with 119,380 more rows, and 28 more variables:\n#   arrival_date_week_number <dbl>, arrival_date_day_of_month <dbl>,\n#   stays_in_weekend_nights <dbl>, stays_in_week_nights <dbl>,\n#   adults <dbl>, children <dbl>, babies <dbl>, meal <chr>,\n#   country <chr>, market_segment <chr>, distribution_channel <chr>,\n#   is_repeated_guest <dbl>, previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\nIf I wanted to know the average amount of adults per booking, I would use summarise() like so:\n\n\nsummarise(hotel_data, mean=mean(adults))\n\n\n# A tibble: 1 × 1\n   mean\n  <dbl>\n1  1.86\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:39-04:00",
    "input_file": "zoe-hotel-bookings-dataset.knit.md"
  },
  {
    "path": "posts/2021-08-13-ishas-blog-post/",
    "title": "Isha's Blog Post",
    "description": "Running Blog Post for Course Homeworks",
    "author": [
      {
        "name": "Isha Akshita Mahajan",
        "url": {}
      }
    ],
    "date": "2021-08-13",
    "categories": [],
    "contents": "\n##Introduction\nHello Everybody! My name is Isha and I am starting the DACSS program this summer. I am from India and completed my bachelors in journalism and political science from UMass. I am excited to meet everyone this fall and delve into the world of data and social science.\n##Homework 2\n\n# A tibble: 6 × 4\n  territory       resp    count percent\n  <chr>           <chr>   <dbl>   <dbl>\n1 New South Wales yes   2374362    57.8\n2 New South Wales no    1736838    42.2\n3 Victoria        yes   2145629    64.9\n4 Victoria        no    1161098    35.1\n5 Queensland      yes   1487060    60.7\n6 Queensland      no     961015    39.3\n\n#About the Data This data sample is drawn from the Australian Marriage Law Postal Survey in 2017. Eligible participants were those who enrolled in the Commonwealth Electoral Roll by August 24 , 2017 and were 18 years of Age. They had not served prison sentences of three years and longer and participated in the survey voluntarily. The responses were recorded to the question\nShould the law be changed to allow same-sex couples to marry?\n##Homework 3\n\nHow can you arrange your dataset by territory?\n\n\n\n\n\nWhich Territory had the highest population count who voted yes to the law allowing same-sex couples to marry.\n\n\n\n\n\nRename the resp column to response.\n\n\n\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:35-04:00",
    "input_file": "ishas-blog-post.knit.md"
  },
  {
    "path": "posts/2021-08-12-wrangling-the-australian-marriage-law-dataset/",
    "title": "Wrangling the Australian marriage law dataset",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Karl Tacheron",
        "url": {}
      }
    ],
    "date": "2021-08-12",
    "categories": [],
    "contents": "\nThe Australian Bureau of Statistics 2017 Marriage Law Postal survey contains data about a nationwide vote that took place by mail. The data has a few things making reading into a tibble difficult:\nGrouped information instead of individual observations where variables appear elsewhere\nMany extraneous & repeated calculated variables\nMulti-index data formatted visually into blocks\nMulti-index column names with confusing and unhelpful names\nTo make this data usable we must transform its structure in both its column layout and its rows.\nWe read in the Excel file’s third sheet, cut it down to only the needed variables and rows, rename the columns, and remove NA values. We also remove rows that contain section totals.\n\n\nlibrary(tidyverse)\nlibrary(readxl)\n\nvotes <- read_excel(\"../../_data/australian_marriage_law_postal_survey_2017_-_response_final.xls\",\n           sheet=\"Table 2\",\n           skip=7,\n           col_names = c(\"Town\", \"Yes\", \"d\", \"No\", rep(\"d\", 6), \"Illegible\", \"d\", \"No Response\", rep(\"d\", 3)))%>%\n  select(!starts_with(\"d\"))%>%\n  drop_na(Town)%>%\n  filter(!str_detect(Town, \"(Total)\"))%>%\n  filter(!str_starts(Town, \"\\\\(\"))\n\n\n\nThe last step is more complicated. Each observation needs a variable for is administrative “division”, but this is displayed at the top of each block. These junk rows listing the parent division names must be turned into a variable for each row.\nWe get the number of each row that contains \" Divisions\".\n\n\nvotes<- votes%>%\n  mutate(Divisions = case_when(\n    str_ends(Town, \"Divisions\") ~ Town,\n    TRUE ~ NA_character_\n  ))\n\nfor(i in 1:length(votes$Divisions)){\n  votes$Divisions[i]<-ifelse(is.na(votes$Divisions[i]),votes$Divisions[i-1], votes$Divisions[i])\n}\n\nvotes<- filter(votes,!str_detect(Town, \"Divisions|Australia\"))\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:34-04:00",
    "input_file": "wrangling-the-australian-marriage-law-dataset.knit.md"
  },
  {
    "path": "posts/2021-08-12-alligator-food/",
    "title": "Alligator Food",
    "description": "The diet of Alligators throughout several different lakes. Data has the lake, sex of alligator, size of food, and species of animal used for food.",
    "author": [],
    "date": "2021-08-12",
    "categories": [],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:31-04:00",
    "input_file": "alligator-food.knit.md"
  },
  {
    "path": "posts/2021-08-12-leahs-first-post-attempt-4/",
    "title": "Leah's first post: Attempt 4",
    "description": "My first blog post.",
    "author": [
      {
        "name": "Leah Dion",
        "url": {}
      }
    ],
    "date": "2021-08-12",
    "categories": [
      ".ruminating .random"
    ],
    "contents": "\nEducation/Work Background: I worked in retail management for many years and am currently entering my final semester to finish my undergraduate degree in Math/Stats.\nProgram: DACSS\nR experience: I used R for several classes and did several projects in the past few years.\nResearch interests: Public Policy, machine learning, criminal punishment system, and social movements\nHometown: South Hadley, MA\nHobbies: Music, basketball, spending time with my cat Jordan.\nFun fact: I have bowled a perfect game (300).\nBelow is a scatter plot of 250 randomly generated data points.\n\n\nknitr::opts_chunk$set(echo = TRUE)\n#set seed to reproduce results\nset.seed(327)\n#randomly generate 250 int from 1-100\nX <- sample.int(100, 250, replace=TRUE) \n#randomly generate 250 int from 1-100\nY <- sample.int(100, 250, replace=TRUE)\n#scatter plot of X, Y\nplot(X, Y, xlab=\"X Samples\", ylab=\"Y Samples\",\n     pch = 16, col = \"red\")\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-08-12-leahs-first-post-attempt-4/leahs-first-post-attempt-4_files/figure-html5/setup-1.png",
    "last_modified": "2021-08-18T15:30:32-04:00",
    "input_file": "leahs-first-post-attempt-4.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-11-2012-us-railroad-employment/",
    "title": "2012 US Railroad Employment",
    "description": "This is Shih-Yen's post on importing and tidying data",
    "author": [],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\nHello, in this post, I will introduce the 2012 US Railroad Employment data, discuss some of the issues with the data, and provide the R code I used to import and tidy the data.\nFirst, let’s download the data. Since the data is in a .xls file, I used the readxl library that comes with the tidyverse package to import the data.\nlibrary(readxl)\nrailroad_data <- read_excel(\"StateCounty2012.xls\")\nview(railroad_data)\nWhen viewing the data, you might first see that the column names for the variables are incorrect and the correct column names are actually in the third row. This error occurs because there are 3 lines of metadata at the top of the file, and read_excel uses the first line as the column names. To fix this problem, we can use skip = 3 in read_excel to skip the first 3 lines.\nrailroad_data <- read_excel(\"StateCounty2012.xls\", skip = 3)\nNext, you might also see that there are two columns, column 2 and 4, that have nothing but NA as values. Here’s an easy way to get rid of those columns:\nrailroad_data <- railroad_data[,-c(2, 4)]\nFinally, it is likely that we are only interested in U.S. county-level data, but our data file also contains rows for state totals, a row for Canada, and a row for the grand total employment in U.S railroads. In addition, there are notes and footnotes that are not useful for the purpose of data analysis.\nTo get of these rows, I use the fact that all of these rows contain entries that have NA as a value, and the rows we want to keep do not. Hence, to clean our data of these rows, we simply get rid of any rows that contain NA as a value. We can achieve that with the following line of code that subsets the railroad_data by omitting all the rows containing NA:\nrailroad_data_clean <- na.omit(railroad_data)\nNow, we have a county-level data set with clearly defined column/variable names.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:16-04:00",
    "input_file": "2012-us-railroad-employment.knit.md"
  },
  {
    "path": "posts/2021-08-11-blog-1/",
    "title": "Larri Miller: Intro to [ ] Dataset",
    "description": "Blog Post 1",
    "author": [
      {
        "name": "Larri Miller",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [
      "Dataset type"
    ],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:17-04:00",
    "input_file": "blog-1.knit.md"
  },
  {
    "path": "posts/2021-08-11-first-post/",
    "title": "[First Post]",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Abhijit",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:20-04:00",
    "input_file": "first-post.knit.md"
  },
  {
    "path": "posts/2021-08-11-hw1/",
    "title": "HW1",
    "description": "A short description of the post.",
    "author": [],
    "date": "2021-08-11",
    "categories": [
      "homework 1",
      "Antonis Gounalakis"
    ],
    "contents": "\n\n\nknitr::opts_chunk$set(echo = FALSE)\n\nvac_tn <- c(52.01,39.84,33.42,5.8,7.29,4.73,4.29,0.55)\npop <- c(83.78,60.46,46.75,10.42,10.2,8.65,5.79,0.89)\nvac_sh <- vac_tn/pop\nperc_vac_sh <- vac_sh*100\nperc_vac_sh > 70\n\n\n[1] FALSE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE\n\nAssuming that each vaccine dose provides full immunity and therefore is administered to different individuals, I examined the vaccination rates of 8 countries (Germany, Italy, Spain, Greece, Portugal, Switzerland, Denmark, Cypurs). I found that only in 3 cases (Spain, Portugal,Denmark) the herd immunity threshold of 70% has been reached!\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:22-04:00",
    "input_file": "hw1.knit.md"
  },
  {
    "path": "posts/2021-08-11-larri-miller-exploring-australian-marriage/",
    "title": "Larri Miller - Exploring Australian Marriage",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Larri Miller",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\nHere I am reading in my CSV file.\n\n        territory resp   count percent\n1 New South Wales  yes 2374362    57.8\n2 New South Wales   no 1736838    42.2\n3        Victoria  yes 2145629    64.9\n4        Victoria   no 1161098    35.1\n5      Queensland  yes 1487060    60.7\n6      Queensland   no  961015    39.3\n\nThis dataset explores Australian marriage. It has 16 observations of 4 variables.\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:25-04:00",
    "input_file": "larri-miller-exploring-australian-marriage.knit.md"
  },
  {
    "path": "posts/2021-08-11-loading-data/",
    "title": "Loading a data set",
    "description": "Homework assignment to load data in to a R Markdown file.",
    "author": [
      {
        "name": "Karl Tacheron",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\nLoad the tidyverse library:\n\n\nlibrary(tidyverse)\n\n\n\nImport a sample data set from the working directory and assign it to variable poultry:\n\n\npoultry<-read_csv('data/poultry_tidy.csv') \n\n\n\nFixed direction of the assignment - Meredith\nShow the first few values:\n\n\nhead(poultry)\n\n\n# A tibble: 6 × 4\n  Product  Year Month    Price_Dollar\n  <chr>   <dbl> <chr>           <dbl>\n1 Whole    2013 January          2.38\n2 Whole    2013 February         2.38\n3 Whole    2013 March            2.38\n4 Whole    2013 April            2.38\n5 Whole    2013 May              2.38\n6 Whole    2013 June             2.38\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:27-04:00",
    "input_file": "loading-data.knit.md"
  },
  {
    "path": "posts/2021-08-11-noahdata/",
    "title": "Noah_Chicken_Data",
    "description": "Included is a brief analysis of chicken data with a plot between year and the average price of each cut of chicken.",
    "author": [
      {
        "name": "Noah Milstein",
        "url": "http://umass.edu/sbs/dacss"
      }
    ],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\n\n\n\n\n\npoultry <- read_csv(\"../../_data/eggs_tidy.csv\")\n\n\n\n\n\npoultry \n\n\n# A tibble: 120 × 6\n   month      year large_half_dozen large_dozen extra_large_half_dozen\n   <chr>     <dbl>            <dbl>       <dbl>                  <dbl>\n 1 January    2004             126         230                    132 \n 2 February   2004             128.        226.                   134.\n 3 March      2004             131         225                    137 \n 4 April      2004             131         225                    137 \n 5 May        2004             131         225                    137 \n 6 June       2004             134.        231.                   137 \n 7 July       2004             134.        234.                   137 \n 8 August     2004             134.        234.                   137 \n 9 September  2004             130.        234.                   136.\n10 October    2004             128.        234.                   136.\n# … with 110 more rows, and 1 more variable: extra_large_dozen <dbl>\n\nNote: This code isn’t running because the variables you are using aren’t in the original csv that I found - but this might be because you are using the poultry file not the eggs file. Sorry I couldn’t get it to work - Meredith\n\n\n#poultry %>% group_by(year, Price_Dollar, Product) %>% ggplot() +\n#  geom_line(mapping=aes(y=Price_Dollar, x=Year, color=Product), na.rm=TRUE)\n\n\n\nChicken Data Conclusion\nThe graph above suggests that the price of most chicken cuts remain relatively similar over time, however B/S Breast or boneless chicken breast appears to have increased in price over recent years. Thighs have also remained relatively similar\nNoah Milstein\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:28-04:00",
    "input_file": "noahdata.knit.md"
  },
  {
    "path": "posts/2021-08-11-post-1-hmwk-1/",
    "title": "Post 1 HMWK 1",
    "description": "This is my post for the first homework",
    "author": [
      {
        "name": "Annie McGrew",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [
      "homework 1",
      "Annie McGrew"
    ],
    "contents": "\n\n\nknitr::opts_chunk$set(echo = FALSE)\nvector <- c(1,2,3,4,5)\nnew_vector <- c(3,5,1,1,2)\navg_vector <- (vector + new_vector)/2\nperc_vector <- avg_vector/5\nfinal_vector <- perc_vector*100\n\n\n\nFirst I input two vectors: vector = 1, 2, 3, 4, 5 and new_vector = 3, 5, 1, 1, 2 Then I take the average of these two vectors creating avg_vector = 2, 3.5, 2, 2.5, 3.5 Then I divide the average of the vectors by 5 (perc_vector = 0.4, 0.7, 0.4, 0.5, 0.7) and finally I multiple the vector by 100 (final_vector = 40, 70, 40, 50, 70).\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:30-04:00",
    "input_file": "post-1-hmwk-1.knit.md"
  },
  {
    "path": "posts/2021-08-11-iris/",
    "title": "Arbitrary",
    "description": "My life in DACSS and with MAX :)",
    "author": [
      {
        "name": "Abhinav Kumar",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\n\n\n# Analysis of Iris\n\nlibrary(datasets)\n\nsummary(iris)\n\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\nplot(iris)\n\n\n\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": "posts/2021-08-11-iris/Abhinav_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-08-18T15:30:24-04:00",
    "input_file": "Abhinav.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-17-jason-wierzbowski-exploring-eggs/",
    "title": "Jason Wierzbowski - Exploring Eggs",
    "description": "A data set about eggs.",
    "author": [
      {
        "name": "Jason Wierzbowski",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\nReading in my CSV file\n\n\n\nHomework #3\n\n# A tibble: 6 × 6\n  month     year large_half_dozen large_dozen extra_large_half_dozen\n  <chr>    <dbl>            <dbl>       <dbl>                  <dbl>\n1 January   2004             126         230                    132 \n2 February  2004             128.        226.                   134.\n3 March     2004             131         225                    137 \n4 April     2004             131         225                    137 \n5 May       2004             131         225                    137 \n6 June      2004             134.        231.                   137 \n# … with 1 more variable: extra_large_dozen <dbl>\n# A tibble: 1 × 2\n  `mean(extra_large_dozen)` `mean(extra_large_half_dozen)`\n                      <dbl>                          <dbl>\n1                      287.                           186.\n\nWorking on Regression of if certain months have an impact on the number of eggs produced\n\n# A tibble: 20 × 6\n# Groups:   month [2]\n   month    year large_half_dozen large_dozen extra_large_half_dozen\n   <chr>   <dbl>            <dbl>       <dbl>                  <dbl>\n 1 January  2004             126         230                    132 \n 2 July     2004             134.        234.                   137 \n 3 January  2005             128.        234.                   136.\n 4 July     2005             128.        234.                   136.\n 5 January  2006             128.        234.                   136.\n 6 July     2006             128.        234.                   136.\n 7 January  2007             128.        234.                   136.\n 8 July     2007             132         237                    139 \n 9 January  2008             132         237                    139 \n10 July     2008             174.        278.                   186.\n11 January  2009             174.        278.                   186.\n12 July     2009             174.        278.                   186.\n13 January  2010             174.        272.                   186.\n14 July     2010             174.        268                    186.\n15 January  2011             174.        268.                   186.\n16 July     2011             174.        270                    186.\n17 January  2012             174.        268.                   186.\n18 July     2012             173.        268.                   186.\n19 January  2013             178         268.                   188.\n20 July     2013             178         268.                   188.\n# … with 1 more variable: extra_large_dozen <dbl>\n\nThis data set contains information on how many half dozens and dozens of eggs made to be sold in a given month of a given year.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:55-04:00",
    "input_file": "jason-wierzbowski-exploring-eggs.knit.md"
  },
  {
    "path": "posts/2021-08-18-rhyslongeggs/",
    "title": "Rhys_Long_Eggs",
    "description": "This is a data set that includes records of how many cartons of eggs were sold every month in 2004-2013. I got this data from the Basic Data sets section of google classroom. This data set contains four variables.",
    "author": [
      {
        "name": "Rhys Long",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\nPart 1: Full Dataset\n\n\nlibrary(tidyverse)\nlibrary(ggplot2)\neggs_data <- read.csv(file = \"../../_data/eggs_tidy.csv\")\ntibble(eggs_data)\n\n\n# A tibble: 120 × 6\n   month      year large_half_dozen large_dozen extra_large_half_dozen\n   <chr>     <int>            <dbl>       <dbl>                  <dbl>\n 1 January    2004             126         230                    132 \n 2 February   2004             128.        226.                   134.\n 3 March      2004             131         225                    137 \n 4 April      2004             131         225                    137 \n 5 May        2004             131         225                    137 \n 6 June       2004             134.        231.                   137 \n 7 July       2004             134.        234.                   137 \n 8 August     2004             134.        234.                   137 \n 9 September  2004             130.        234.                   136.\n10 October    2004             128.        234.                   136.\n# … with 110 more rows, and 1 more variable: extra_large_dozen <dbl>\n\nggplot(data = eggs_data, aes(year)) +\n  geom_point(mapping = aes(y=extra_large_dozen), color = 'magenta') +\n  geom_point(mapping = aes(y=large_dozen), color = 'purple') +\n  geom_point(mapping = aes(y=extra_large_half_dozen), color = 'blue') +\n  geom_point(mapping = aes(y=large_half_dozen), color = 'cyan') +\n  labs(title=\"Eggs Sales in 2004-2013\", y=\"Eggs Sold\", x=\"Year\")\n\n\n\n\nPart 2: Using Filter And Summarize\n\n\nfirst_third <- filter(eggs_data, year <= 2007)\nggplot(data = first_third, aes(year)) +\n  geom_point(mapping = aes(y=extra_large_dozen), color = 'magenta') +\n  geom_point(mapping = aes(y=large_dozen), color = 'purple') +\n  geom_point(mapping = aes(y=extra_large_half_dozen), color = 'blue') +\n  geom_point(mapping = aes(y=large_half_dozen), color = 'cyan') +\n  labs(title=\"Eggs Sales in 2004-2007\", y=\"Earnings\", x=\"Year\")\n\n\n\nsummarize(first_third, max(extra_large_dozen), min(extra_large_dozen), median(extra_large_dozen), mean(extra_large_dozen))\n\n\n  max(extra_large_dozen) min(extra_large_dozen)\n1                    245                    230\n  median(extra_large_dozen) mean(extra_large_dozen)\n1                       241                241.0833\n\nsummarize(first_third, max(large_dozen), min(large_dozen), median(large_dozen), mean(large_dozen))\n\n\n  max(large_dozen) min(large_dozen) median(large_dozen)\n1              237              225               233.5\n  mean(large_dozen)\n1          233.4844\n\nsummarize(first_third, max(extra_large_half_dozen), min(extra_large_half_dozen), median(extra_large_half_dozen), mean(extra_large_half_dozen))\n\n\n  max(extra_large_half_dozen) min(extra_large_half_dozen)\n1                         139                         132\n  median(extra_large_half_dozen) mean(extra_large_half_dozen)\n1                          135.5                     136.3854\n\nsummarize(first_third, max(large_half_dozen), min(large_half_dozen), median(large_half_dozen), mean(large_half_dozen))\n\n\n  max(large_half_dozen) min(large_half_dozen)\n1                 133.5                   126\n  median(large_half_dozen) mean(large_half_dozen)\n1                    128.5               129.7266\n\n\n\nmiddle_third <- filter(eggs_data, year >= 2007 & year <=2010)\nggplot(data = middle_third, aes(year)) +\n  geom_point(mapping = aes(y=extra_large_dozen), color = 'magenta') +\n  geom_point(mapping = aes(y=large_dozen), color = 'purple') +\n  geom_point(mapping = aes(y=extra_large_half_dozen), color = 'blue') +\n  geom_point(mapping = aes(y=large_half_dozen), color = 'cyan') +\n  labs(title=\"Eggs Sales in 2007-2010\", y=\"Earnings\", x=\"Year\")\n\n\n\nsummarize(middle_third, max(extra_large_dozen), min(extra_large_dozen), median(extra_large_dozen), mean(extra_large_dozen))\n\n\n  max(extra_large_dozen) min(extra_large_dozen)\n1                  285.5                  241.5\n  median(extra_large_dozen) mean(extra_large_dozen)\n1                     285.5                271.0651\n\nsummarize(middle_third, max(large_dozen), min(large_dozen), median(large_dozen), mean(large_dozen))\n\n\n  max(large_dozen) min(large_dozen) median(large_dozen)\n1            277.5            233.5                 268\n  mean(large_dozen)\n1          260.1797\n\nsummarize(middle_third, max(extra_large_half_dozen), min(extra_large_half_dozen), median(extra_large_half_dozen), mean(extra_large_half_dozen))\n\n\n  max(extra_large_half_dozen) min(extra_large_half_dozen)\n1                       185.5                       135.5\n  median(extra_large_half_dozen) mean(extra_large_half_dozen)\n1                          185.5                     168.9401\n\nsummarize(middle_third, max(large_half_dozen), min(large_half_dozen), median(large_half_dozen), mean(large_half_dozen))\n\n\n  max(large_half_dozen) min(large_half_dozen)\n1                 174.5                 128.5\n  median(large_half_dozen) mean(large_half_dozen)\n1                    174.5               159.3568\n\n\n\nfinal_third <- filter(eggs_data, year >=2010)\nggplot(data = final_third, aes(year)) +\n  geom_point(mapping = aes(y=extra_large_dozen), color = 'magenta') +\n  geom_point(mapping = aes(y=large_dozen), color = 'purple') +\n  geom_point(mapping = aes(y=extra_large_half_dozen), color = 'blue') +\n  geom_point(mapping = aes(y=large_half_dozen), color = 'cyan') +\n  labs(title=\"Eggs Sales in 2010-2013\", y=\"Earnings\", x=\"Year\")\n\n\n\nsummarize(final_third, max(extra_large_dozen), min(extra_large_dozen), median(extra_large_dozen), mean(extra_large_dozen))\n\n\n  max(extra_large_dozen) min(extra_large_dozen)\n1                    290                  285.5\n  median(extra_large_dozen) mean(extra_large_dozen)\n1                     285.5                 287.375\n\nsummarize(final_third, max(large_dozen), min(large_dozen), median(large_dozen), mean(large_dozen))\n\n\n  max(large_dozen) min(large_dozen) median(large_dozen)\n1            271.5            267.5               267.5\n  mean(large_dozen)\n1          268.1042\n\nsummarize(final_third, max(extra_large_half_dozen), min(extra_large_half_dozen), median(extra_large_half_dozen), mean(extra_large_half_dozen))\n\n\n  max(extra_large_half_dozen) min(extra_large_half_dozen)\n1                      188.13                       185.5\n  median(extra_large_half_dozen) mean(extra_large_half_dozen)\n1                          185.5                     186.2671\n\nsummarize(final_third, max(large_half_dozen), min(large_half_dozen), median(large_half_dozen), mean(large_half_dozen))\n\n\n  max(large_half_dozen) min(large_half_dozen)\n1                   178                173.25\n  median(large_half_dozen) mean(large_half_dozen)\n1                    174.5               175.3646\n\nPart 3: Using Select, Slice, and Arrange\n\n\neggs_data %>%\n  select(month, year, extra_large_dozen) %>%\n  arrange(desc(extra_large_dozen)) %>%\n  slice(1:10)\n\n\n      month year extra_large_dozen\n1  November 2012               290\n2  December 2012               290\n3   January 2013               290\n4  February 2013               290\n5     March 2013               290\n6     April 2013               290\n7       May 2013               290\n8      June 2013               290\n9      July 2013               290\n10   August 2013               290\n\nggplot(data = eggs_data, aes(year)) +\n  geom_point(mapping = aes(y=extra_large_dozen), color = 'magenta') +\n  labs(title=\"Extra Large Dozen Egg Sales in 2004-2013\", y=\"Earnings\", x=\"Year\")\n\n\n\n\n\n\neggs_data %>%\n  select(month, year, large_dozen) %>%\n  arrange(desc(large_dozen)) %>%\n  slice(1:10)\n\n\n       month year large_dozen\n1       June 2008       277.5\n2       July 2008       277.5\n3     August 2008       277.5\n4  September 2008       277.5\n5    October 2008       277.5\n6   November 2008       277.5\n7   December 2008       277.5\n8    January 2009       277.5\n9   February 2009       277.5\n10     March 2009       277.5\n\nggplot(data = eggs_data, aes(year)) +\n  geom_point(mapping = aes(y=large_dozen), color = 'purple') +\n  labs(title=\"Large Dozen Egg Sales in 2004-2013\", y=\"Earnings\", x=\"Year\")\n\n\n\n\n\n\neggs_data %>%\n  select(month, year, extra_large_half_dozen) %>%\n  arrange(desc(extra_large_half_dozen)) %>%\n  slice(1:10)\n\n\n      month year extra_large_half_dozen\n1  November 2012                 188.13\n2  December 2012                 188.13\n3   January 2013                 188.13\n4  February 2013                 188.13\n5     March 2013                 188.13\n6     April 2013                 188.13\n7       May 2013                 188.13\n8      June 2013                 188.13\n9      July 2013                 188.13\n10   August 2013                 188.13\n\nggplot(data = eggs_data, aes(year)) +\n  geom_point(mapping = aes(y=extra_large_half_dozen), color = 'blue') +\n  labs(title=\"Extra Large Half Dozen Egg Sales in 2004-2013\", y=\"Earnings\", x=\"Year\")\n\n\n\n\n\n\neggs_data %>%\n  select(month, year, large_half_dozen) %>%\n  arrange(desc(large_half_dozen)) %>%\n  slice(1:10)\n\n\n      month year large_half_dozen\n1  November 2012              178\n2  December 2012              178\n3   January 2013              178\n4  February 2013              178\n5     March 2013              178\n6     April 2013              178\n7       May 2013              178\n8      June 2013              178\n9      July 2013              178\n10   August 2013              178\n\nggplot(data = eggs_data, aes(year)) +\n  geom_point(mapping = aes(y=large_half_dozen), color = 'cyan') +\n  labs(title=\"Large Half Dozen Egg Sales in 2004-2013\", y=\"Earnings\", x=\"Year\")\n\n\n\n\nPart 4: Using Rename, Pivot_Longer, and Mutate\n\n\neggs_data %>%\n  rename(\"Month\"=month, \"Year\"=year) %>%\n  pivot_longer(cols=large_half_dozen:extra_large_dozen,\n               names_to = c(\"Size\", \"Quantity\"),\n               names_sep=\"arge_\",\n               values_to = \"Earnings\")%>%\n  mutate(Size = case_when(\n    Size == 'l'~\"Large\",\n    Size == 'extra_l'~ \"Extra Large\")) %>%\n  mutate(Quantity=case_when(\n    Quantity == \"half_dozen\" ~ \"Half Dozen\",\n    Quantity == \"dozen\" ~ \"Dozen\"))\n\n\n# A tibble: 480 × 5\n   Month     Year Size        Quantity   Earnings\n   <chr>    <int> <chr>       <chr>         <dbl>\n 1 January   2004 Large       Half Dozen     126 \n 2 January   2004 Large       Dozen          230 \n 3 January   2004 Extra Large Half Dozen     132 \n 4 January   2004 Extra Large Dozen          230 \n 5 February  2004 Large       Half Dozen     128.\n 6 February  2004 Large       Dozen          226.\n 7 February  2004 Extra Large Half Dozen     134.\n 8 February  2004 Extra Large Dozen          230 \n 9 March     2004 Large       Half Dozen     131 \n10 March     2004 Large       Dozen          225 \n# … with 470 more rows\n\n\n\n\n",
    "preview": "posts/2021-08-18-rhyslongeggs/rhyslongeggs_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-08-18T15:31:05-04:00",
    "input_file": "rhyslongeggs.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-10-cars/",
    "title": "iris",
    "description": "iris dataset| ErinTracy",
    "author": [],
    "date": "2021-08-10",
    "categories": [
      "-homework 3"
    ],
    "contents": "\nColumn 1\nWidth\n\n\nggplot(iris, aes(Petal.Width)) + geom_histogram(binwidth = 0.1)\n\n\n\n\nlength\n\n\nggplot(iris, aes(Petal.Length)) + geom_bar()\n\n\n\n\nSpecies\n\n\nggplot(iris, aes(Species)) + geom_bar()\n\n\n\n\nColumn 2\nThe largest iris\n\n\niris %>% \n  arrange(desc(Petal.Length)) %>% \n  head(100) %>% \n  select(Petal.Length, Petal.Width, Species) %>% \n  DT::datatable()\n\n\n\n{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\"],[6.9,6.7,6.7,6.6,6.4,6.3,6.1,6.1,6.1,6,6,5.9,5.9,5.8,5.8,5.8,5.7,5.7,5.7,5.6,5.6,5.6,5.6,5.6,5.6,5.5,5.5,5.5,5.4,5.4,5.3,5.3,5.2,5.2,5.1,5.1,5.1,5.1,5.1,5.1,5.1,5.1,5,5,5,5,4.9,4.9,4.9,4.9,4.9,4.8,4.8,4.8,4.8,4.7,4.7,4.7,4.7,4.7,4.6,4.6,4.6,4.5,4.5,4.5,4.5,4.5,4.5,4.5,4.5,4.4,4.4,4.4,4.4,4.3,4.3,4.2,4.2,4.2,4.2,4.1,4.1,4.1,4,4,4,4,4,3.9,3.9,3.9,3.8,3.7,3.6,3.5,3.5,3.3,3.3,3],[2.3,2.2,2,2.1,2,1.8,2.5,1.9,2.3,2.5,1.8,2.1,2.3,2.2,1.8,1.6,2.3,2.1,2.5,1.8,2.1,2.2,1.4,2.4,2.4,2.1,1.8,1.8,2.1,2.3,1.9,2.3,2.3,2,1.6,1.9,2,2.4,1.5,2.3,1.9,1.8,1.7,2,1.5,1.9,1.5,1.5,2,1.8,1.8,1.8,1.4,1.8,1.8,1.4,1.6,1.4,1.2,1.5,1.5,1.3,1.4,1.5,1.3,1.5,1.5,1.5,1.5,1.6,1.7,1.4,1.4,1.3,1.2,1.3,1.3,1.5,1.3,1.2,1.3,1,1.3,1.3,1.3,1,1.3,1.3,1.2,1.4,1.1,1.2,1.1,1,1.3,1,1,1,1,1.1],[\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"versicolor\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"versicolor\",\"virginica\",\"virginica\",\"virginica\",\"versicolor\",\"versicolor\",\"virginica\",\"virginica\",\"virginica\",\"versicolor\",\"versicolor\",\"virginica\",\"virginica\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"virginica\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Petal.Length<\\/th>\\n      <th>Petal.Width<\\/th>\\n      <th>Species<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\n\n\n\n",
    "preview": "posts/2021-08-10-cars/cars_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-08-18T15:29:58-04:00",
    "input_file": "cars.knit.md",
    "preview_width": 960,
    "preview_height": 320
  },
  {
    "path": "posts/2021-08-10-hello-world/",
    "title": "Hello World",
    "description": "Marina's first attempt at using distill",
    "author": [
      {
        "name": "Marina",
        "url": {}
      }
    ],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\nTime to read in data. Start with an easy one\n\n\n\n\n# A tibble: 6 × 32\n  hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n  <chr>              <dbl>     <dbl>            <dbl> <chr>           \n1 Resort Hotel           0       342             2015 July            \n2 Resort Hotel           0       737             2015 July            \n3 Resort Hotel           0         7             2015 July            \n4 Resort Hotel           0        13             2015 July            \n5 Resort Hotel           0        14             2015 July            \n6 Resort Hotel           0        14             2015 July            \n# … with 27 more variables: arrival_date_week_number <dbl>,\n#   arrival_date_day_of_month <dbl>, stays_in_weekend_nights <dbl>,\n#   stays_in_week_nights <dbl>, adults <dbl>, children <dbl>,\n#   babies <dbl>, meal <chr>, country <chr>, market_segment <chr>,\n#   distribution_channel <chr>, is_repeated_guest <dbl>,\n#   previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\nTry a harder one: an excel file with a number of useless rows\n\n# A tibble: 6 × 17\n  blank pay_grade SWOC_male SWOC_female SWOC_total SWC_male SWC_female\n  <chr> <chr>         <dbl>       <dbl>      <dbl>    <dbl>      <dbl>\n1 <NA>  E-1           31229        5717      36946      563        122\n2 <NA>  E-2           53094        8388      61482     1457        275\n3 <NA>  E-3          131091       21019     152110     4264       1920\n4 <NA>  E-4          112710       16381     129091     9491       4662\n5 <NA>  E-5           57989       11021      69010    10937       6576\n6 <NA>  E-6           19125        4654      23779    10369       4962\n# … with 10 more variables: SWC_total <dbl>, JSM_male <dbl>,\n#   JSM_female <dbl>, JSM_total <dbl>, CM_male <dbl>,\n#   CM_female <dbl>, CM_total <dbl>, Total_Male <dbl>,\n#   Total_Female <dbl>, Total_Total <dbl>\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:02-04:00",
    "input_file": "hello-world.knit.md"
  },
  {
    "path": "posts/2021-08-10-homework-1/",
    "title": "Homework 1",
    "description": "Homework 1",
    "author": [],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\nHello, my name is Shih-Yen Pan. I am a PhD student in Economics at UMass, Amherst.\nIn this post, I will introduce the Two Sum problem from LeetCode and a solution using double for loop provided by Pascal Schmidt here. I thought it might be useful to see what for loop looks like in R.\nThe idea of the problem is, given a list of integers nums and an integer target, to write a function that spits out, if they exist, two different integers in nums that sum up to the target integer.\ntwo_sum <- function(nums, target) {\n\n  for(i in seq_along(nums)) {\n    for(j in seq_along(nums)[-length(nums)]) {\n      \n      sum <- nums[i] + nums[j + 1]\n      if(sum == target) {\n        \n        first <- i\n        second <- j + 1\n        output <- c(nums[first], nums[second])\n        return(output)\n        \n      }\n      \n    }\n    \n  }\n  \n}\nThis is what the function two_sum is doing: Starting from the beginning of the vector ‘nums’, for each integer, search the rest of vector using the second for loop. If the two numbers sum up to the target integer, the code returns those two numbers; otherwise, continue doing the same with the next integer in the list.\nExample:\nnums <- c(1, 2, 3, 5, 6, 9, 11)\ntarget <- 9\ntwo_sum(nums, target)\nThis should return 3 and 6.\nTry it out yourself with different numbers! How can the code be modified to return all the different pairs that sum to the target integer?\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:03-04:00",
    "input_file": "homework-1-Shih-Yen.knit.md"
  },
  {
    "path": "posts/2021-08-10-hw01/",
    "title": "HW01",
    "description": "A short description of the post.",
    "author": [],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:04-04:00",
    "input_file": "hw01.knit.md"
  },
  {
    "path": "posts/2021-08-10-iris/",
    "title": "iris",
    "description": "Here is the iris dataset.",
    "author": [
      {
        "name": "bakharia",
        "url": {}
      }
    ],
    "date": "2021-08-10",
    "categories": [
      "homework 3",
      "iris",
      "bakharia"
    ],
    "contents": "\nHere is a plot of the iris dataset:\n\n\nlibrary(datasets)\nplot(iris)\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-08-10-iris/iris_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-08-18T15:30:06-04:00",
    "input_file": "iris.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-10-meet-rhys/",
    "title": "Meet Rhys",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Rhys Long",
        "url": {}
      }
    ],
    "date": "2021-08-10",
    "categories": [
      "homework one",
      "introduce yourself",
      "rhys long"
    ],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:07-04:00",
    "input_file": "meet-rhys.knit.md"
  },
  {
    "path": "posts/2021-08-10-michelle-manning/",
    "title": "Michelle Manning",
    "description": "Intro for me.",
    "author": [
      {
        "name": "Michelle Manning",
        "url": {}
      }
    ],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\n\n\nlibrary(dslabs)\ndata(\"gapminder\")\nlibrary(dplyr)\nlibrary(ggplot2)\n\n\n\n\n\ngapminder %>% \n  select(continent, region, gdp, population) %>%\n  mutate(gdp_per_capita = gdp / population) %>% \n  arrange(desc(gdp_per_capita)) %>%\n  ggplot(aes(x=gdp_per_capita)) + \n  geom_histogram(binwidth = 30)\n\n\n\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": "posts/2021-08-10-michelle-manning/michelle-manning_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-08-18T15:30:09-04:00",
    "input_file": "michelle-manning.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-10-noahblogpost/",
    "title": "Noahblogpost",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Noah Milstein",
        "url": {}
      }
    ],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\n\n\n8+8\n\n\n[1] 16\n\n\n\n8==2\n\n\n[1] FALSE\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:11-04:00",
    "input_file": "noahblogpost.knit.md"
  },
  {
    "path": "posts/2021-08-10-test/",
    "title": "TEST",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "bakharia",
        "url": {}
      }
    ],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:12-04:00",
    "input_file": "test.knit.md"
  },
  {
    "path": "posts/2021-08-10-title/",
    "title": "title",
    "description": "A short description of the post.",
    "author": [],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:13-04:00",
    "input_file": "title.knit.md"
  },
  {
    "path": "posts/2021-08-10-zoes-post/",
    "title": "Zoe's Post",
    "description": "my first post",
    "author": [
      {
        "name": "Zoe Bean",
        "url": {}
      }
    ],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\nHi! I’m Zoe. I really like for loops. Here’s one in R!\n\n\ncool_sequence<-c(1,1,2,3,5,8,13,21,34)\ntotal<-0\nfor (el in cool_sequence) {\n  total=total+el\n}\nprint(total)\n\n\n[1] 88\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:30:15-04:00",
    "input_file": "zoes-post.knit.md"
  },
  {
    "path": "posts/2021-08-07-still-learning-githib-workflow/",
    "title": "Still Learning the GitHib Workflow",
    "description": "Fingers crossed this post works",
    "author": [
      {
        "name": "Maddi Hertz",
        "url": {}
      }
    ],
    "date": "2021-08-07",
    "categories": [],
    "contents": "\nUsing Markdown is fun!\nI learned a lot this summer — Markdown is your friend, as are flexdashboard and Stack Overflow.\nAlso, always keep in mind that social scientists understand data and data management just as well (if not better) than the computer scientists.\nTidyTuesday\nNew goal: Participate in Tidy Tuesdays\nExample of R Chunk\n\n\n2+2\n\n\n[1] 4\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:29:54-04:00",
    "input_file": "still-learning-githib-workflow.knit.md"
  },
  {
    "path": "posts/2021-08-07-welcome/",
    "title": "Welcome to DACSS 601",
    "description": "August 2021 Orientation Session",
    "author": [
      {
        "name": "Meredith Rolfe",
        "url": "http://umass.edu/sbs/dacss"
      }
    ],
    "date": "2021-08-06",
    "categories": [
      "welcome"
    ],
    "contents": "\nWelcome to the Data Analytics and Computational Social Science Programs’ Orientation 2021 session of DACSS 601 Foundations of Data Science. This blog will feature the work of our incoming M.S. students taking the class, as well as PhD students in the College of Behavioral and Social Sciences who have decided to participate through “R Bootcamp”.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:29:56-04:00",
    "input_file": "welcome.knit.md"
  }
]
